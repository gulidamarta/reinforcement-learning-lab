{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Introduction to PyTorch and Behavior Cloning\n",
    "\n",
    "In this exercise, we introduce the fundamental concepts of PyTorch and show how this framework can be applied to build and train custom neural networks. \n",
    "We then utilize these networks to train an agent to play a simple video game from demonstrations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Install packages and dependencies\n",
    "\n",
    "We recommend using a ``conda`` environment (or virtual environments) for this and the follwing exercises. If you are not familiar with Anaconda, you can read this tutorial: [Getting started with conda]( https://conda.io/projects/conda/en/latest/user-guide/getting-started.html). \n",
    "\n",
    "Here's an example of the steps you can take:\n",
    "1. Install a conda distribution on your machine\n",
    "2. Create a new conda Python 3.9 environment with name rl_lab: ``conda create --name rl_lab python=3.9``\n",
    "3. Activate the environment: ``conda activate rl_lab``\n",
    "4. Install dependencies using the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install gymnasium==0.29.1\n",
    "!pip install minatar==1.0.15\n",
    "!pip install matplotlib\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction to PyTorch\n",
    "\n",
    "PyTorch is a Python-based library designed for deep learning. It is distinguished by its dynamic computational graph, which enables researchers and developers to construct models with a high degree of flexibility. PyTorch has found extensive use in various scientific and engineering domains due to its ease of use and extensive research-friendly features.\n",
    "\n",
    "This exercise is based on the [PyTorch 60-Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tensors\n",
    "Tensors are used to encode inputs and outputs of a model, as well as a model's parameters. They are comparable to NumPy's ndarrays, but they have the advantage that PyTorch tensors can run on GPUs and other accelerators. \n",
    "\n",
    "Extra resources: [Intuition behind tensors](https://www.youtube.com/watch?v=f5liqUk0ZTw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1.1 Tensor Initialization**\n",
    "\n",
    "Tensors can be initialized in multiple ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from data: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "Tensor from NumPy array: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "Shape given by another tensor:\n",
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.2236, 0.4149],\n",
      "        [0.8792, 0.7003]]) \n",
      "\n",
      "Shape defined: (2, 3)\n",
      "Random Tensor: \n",
      " tensor([[0.6742, 0.9638, 0.8304],\n",
      "        [0.1027, 0.9990, 0.7408]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# directly from data\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(f\"Tensor from data: \\n {x_data} \\n\")\n",
    "\n",
    "# from a NumPy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(f\"Tensor from NumPy array: \\n {x_np} \\n\")\n",
    "\n",
    "# from another tensor\n",
    "print(\"Shape given by another tensor:\")\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
    "\n",
    "# with random or constant values\n",
    "shape = (2, 3,)\n",
    "print(\"Shape defined:\", shape)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1.2 Tensor Attributes**\n",
    "\n",
    "We can print information such as the tensor shape, the tensor datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1.3 Tensor Operations**\n",
    "\n",
    "For a full list of available tensor operations check out the corresponding [PyTorch documentation](https://pytorch.org/docs/stable/torch.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second column replaced with zeros \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standard numpy-like indexing and slicing\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(f\"Second column replaced with zeros \\n {tensor} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Indexing and Slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted submatrix:\n",
      " tensor([[ 5,  6,  7],\n",
      "        [ 9, 10, 11],\n",
      "        [13, 14, 15]])\n",
      "Tensor after replacement:\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 0,  0,  0,  8],\n",
      "        [ 0,  0,  0, 12],\n",
      "        [ 0,  0,  0, 16]])\n"
     ]
    }
   ],
   "source": [
    "tensor_exercise = torch.tensor([[1, 2, 3, 4],\n",
    "                       [5, 6, 7, 8],\n",
    "                       [9, 10, 11, 12],\n",
    "                       [13, 14, 15, 16]])\n",
    "\n",
    "# Exercise 1: Select the last 3 rows of the first 3 columns and assign them to 'submatrix'\n",
    "submatrix = tensor_exercise[-3:, :3]\n",
    "print(\"Extracted submatrix:\\n\", submatrix)\n",
    "\n",
    "# Exercise 2: Replace the extracted submatrix with a tensor of zeros in the original tensor\n",
    "tensor_exercise[-3:, :3] = torch.zeros(size=submatrix.shape)\n",
    "print(\"Tensor after replacement:\\n\", tensor_exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated tensor \n",
      " tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# joining tensors (concatenation or stacking)\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(f\"Concatenated tensor \\n {t1} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# multiplying tensors\n",
    "# element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")\n",
    "\n",
    "# matrix multiplication\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor before inplace addition \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "Tensor after inplace addition \n",
      " tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inplace operations have a trailing underscore\n",
    "print(f\"Tensor before inplace addition \\n {tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(f\"Tensor after inplace addition \\n {tensor} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Element-wise logarithm, multiplication and calculation of the mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 1.3863, 3.2958, 5.5452])\n",
      "tensor(2.5568)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "# Exercise 1: Calculate the element-wise natural logarithm and multiply the result with the tensor itself\n",
    "log_tensor = torch.log(tensor) * tensor\n",
    "print(log_tensor)\n",
    "\n",
    "# Exercise 2: Calculate the mean of the resulting tensor\n",
    "mean_log = torch.mean(log_tensor)\n",
    "print(mean_log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In-place operations can be problematic when computing derivatives because of a loss of history. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1.4 Bridge with NumPy**\n",
    "\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and a change to one will cause the other to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "# tensor to NumPy array\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "# both arrays are modified\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "# NumPy array to tensor\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "# both arrays are modified\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Introduction to torch.autograd\n",
    "\n",
    "``torch.autograd`` is PyTorch's engine for automatic differentiation. It is essential for the training of neural networks.\n",
    "\n",
    "**1.2.1 Differentiation in Autograd**\n",
    "\n",
    "The argument ``required_grad=True`` signals to ``autograd`` that every operation on those tensors should be tracked. This allows ``autograd`` to collect gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If ``a`` and ``b`` are parameters of a neural networks the error function ``Q`` could looks like this:\n",
    "\n",
    "\\begin{align}Q = 3a^3 - b^2\\end{align}\n",
    "\n",
    "For the training of the neural network we need to calculate the gradients with respect to the parameters: \n",
    "\n",
    "\\begin{align}\\frac{\\partial Q}{\\partial a} = 9a^2\\end{align}\n",
    "\n",
    "\\begin{align}\\frac{\\partial Q}{\\partial b} = -2b\\end{align}\n",
    "\n",
    "With ``autograd`` you can calculate those gradients by calling ``.backward()`` on Q. The ``gradient`` argument is used here to specify how much the tensors ``a`` and ``b`` should influence the gradient calculation of ``Q``. By providing ``external_grad`` as the gradient argument, you ensure that both ``a`` and ``b`` are treated as if they contribute equally to the gradient of ``Q`` (both having a weight of 1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)\n",
    "\n",
    "# check if collected gradients are correct\n",
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **torch.autograd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of x: tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "y = 2 * x[0] + 3 * x[1]\n",
    "\n",
    "# Exercise 1: Calculate gradients\n",
    "y.backward()\n",
    "\n",
    "# Exercise 2: Print gradients of 'x'\n",
    "print(\"Gradients of x:\", x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2.2 Computational Graph**\n",
    "\n",
    "``autograd`` functions by maintaining a record of both data (tensors) and executed operations in a directed acyclic graph (DAG) composed of Function objects. Within this graph structure, the input tensors serve as the starting point (leaves), and the output tensors act as the endpoints (roots). By traversing this graph in a reverse manner, one can automatically compute gradients using the chain rule.\n",
    "\n",
    "- **Forward pass**: ``autograd`` performs operations to compute the resulting tensor and maintains the operation's gradient function in the DAG.\n",
    "\n",
    "- **Backward pass**: ``autograd`` (triggered by calling ``.backward()`` on the DAG root) computes the gradients from each ``.grad_fn``, accumulates them in the corresponding tensor's ``.grad`` attribute, and applies the chain rule to propagate gradients to the leaf tensors.\n",
    "\n",
    "``autograd`` tracks operations for tensors with ``requires_grad=True``, while setting ``requires_grad=False`` excludes them; if any input tensor has ``requires_grad=True``, the output tensor will also require gradients.\n",
    "\n",
    "Note: In PyTorch, DAGs (Directed Acyclic Graphs) are dynamic, and it's important to know that a new graph is built from scratch after each ``.backward()`` call. This flexibility enables the use of control flow statements and the ability to modify the model's shape, size, and operations in each iteration as required.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **DAG**\\\n",
    "Think about the answers before executing the following code. Give an explanation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does `a` require gradients?: False\n",
      "Does `b` require gradients?: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 5)\n",
    "y = torch.rand(5, 5)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "print(f\"Does `a` require gradients?: {a.requires_grad}\")\n",
    "b = x + z\n",
    "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers:** \n",
    "1. In the first case it **does not require** gradient, because for both x and y we have required_grad=False.\n",
    "2. In the second case the resulting b **requires** gradient because one of the tensors (z tensor) requires gradient."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Neural Networks with PyTorch\n",
    "\n",
    "The ``torch.nn`` package can be used to construct neural networks. ``nn.Module``s contain layers, and a method ``forward(input)`` that returns the ``output``.\n",
    "\n",
    "Typical training procedure for a neural network:\n",
    "1. Define neural network with some learnable parameters (weights)\n",
    "2. Iterate over dataset of inputs\n",
    "3. Process input through network\n",
    "4. Compute the loss (how wrong is the output)\n",
    "5. Backpropagate to calculate the gradient for each of the network's weights\n",
    "6. Update the weights of the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.1 Define the network**\n",
    "\n",
    "Define the ``forward`` function. The ``backward`` function is automatically defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Number of learnable parameters: 61706 \n",
      "\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# learnable parameters of the model\n",
    "params = list(net.parameters())\n",
    "n_params = np.sum([torch.numel(p) for p in params])\n",
    "print(f\"Number of learnable parameters: {n_params} \\n\") \n",
    "print(params[0].shape)  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0303,  0.0618,  0.0827, -0.0827, -0.0317, -0.0310,  0.1024,  0.0354,\n",
      "          0.1013,  0.0268]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# random input\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero gradient buffers of all parameters and backprops with random gradients\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.2 Loss Function**\n",
    "\n",
    "The loss function computes a value that estimates how far away the output is from the target. For the full list of available loss functions check out the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html#loss-functions).\n",
    "\n",
    "Example: ``MSELoss`` (mean squared error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8798, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.3 Backprop**\n",
    "\n",
    "To initiate error backpropagation, use ``loss.backward()``, but make sure to clear existing gradients; otherwise, the new gradients will accumulate onto the existing ones. This step is crucial for accurate gradient calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0073, -0.0246, -0.0072, -0.0006,  0.0013,  0.0078])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print(\"conv1.bias.grad before backward\")\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"conv1.bias.grad after backward\")\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.4 Update the weights**\n",
    "\n",
    "A simple update rule is the Stochastic Gradient Descent (SGD):\n",
    "\n",
    "*weight = weight - learning_rate * gradient*\n",
    "\n",
    "The ``torch.optim`` package implements different update rules such as SGB, Nesterov-SGD, Adam, RMSProp, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Neural Networks Recap**\n",
    "1. What is the purpose of the forward method in a PyTorch neural network model?\n",
    "2. How do you define a convolutional layer in PyTorch, and what does the nn.Conv2d module do?\n",
    "3. In the provided code, how many learnable parameters does the neural network model Net have, and how can you access them?\n",
    "4. Explain what happens when you call net.zero_grad() and why it is important.\n",
    "5. What does the optimizer.step() method do, and when is it typically called in the training loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers:** \n",
    "1. It defines the forward pass of the neural networks, it takes the input data and passes it through all layers of the network producing the output. It is commonly used to make predictions or to compute the loss during the training.\n",
    "2. Convolutional layers are defined with **torch.nn.Conv2d**. There are some parameters that you can define while using this method such as **in_features** - how many features are we passing in, **out_features** - how many kernels we want to use, **kernel_size** - the size of the kernel, **stride** - the \"step size\" of the kernel, **padding** - the number of pixels by which we need to extend the image boundary outward to obtain additional edge pixels.\n",
    "**nn.Conv2d** applies a 2D convolution over an input signal composed of several input planes.\n",
    "3. Number of learnable parameters: **61706**. You can access them with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "n_params = np.sum([torch.numel(p) for p in params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **net.zero_grad()** sets the gradients of all its parameters (including parameters of submodules) to zero. If we don't call this method the new gradients will accumulate onto the existing ones. It is important for accurate gradient calculations. Otherwise, the gradient would result from a combination of the previously used gradient (which has already updated the model parameters) and the newly computed gradient. Consequently, it would indicate a direction different from the intended path toward the minimum (or maximum, in the case of maximization objectives). But this accumulating behaviour can be conviniet while training the RNNs.\n",
    "5. **optimizer.step()** make the optimizer to iterate through all the parameters (tensors) it is supposed to update and utilize their internally stored gradients to update their respective values. This method can be called once the gradients are computed using e.g. backward()."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Custom Layer**\\\n",
    "Create  a custom neural network layer called CustomLayer that inherits from nn.Module. The layer should take an input tensor and compute the element-wise square of the input tensor.\n",
    "1. Define the CustomLayer class with an init and a forward method that performs the specified operation.\n",
    "2. Instantiate the CustomLayer.\n",
    "3. Generate a random input tensor with dimensions (1, 3, 4, 4).\n",
    "4. Apply the CustomLayer to the input tensor to calculate the element-wise square.\n",
    "5. Print the input tensor and the resulting output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomLayer()\n",
      "Input Tensor: tensor([[[[-0.2747, -0.0326, -0.9588, -1.0899],\n",
      "          [ 0.9245, -0.5423,  1.6448, -0.1926],\n",
      "          [ 0.7738,  0.2316, -0.9853, -1.6030],\n",
      "          [-0.5493, -0.2440, -2.4237,  0.4265]],\n",
      "\n",
      "         [[-0.1149, -1.6528,  0.1428, -2.3119],\n",
      "          [-0.0283,  1.0120,  1.0528, -0.0503],\n",
      "          [-0.5638, -0.9976, -0.4495,  0.6696],\n",
      "          [-0.9123, -0.8839,  0.2280, -1.3999]],\n",
      "\n",
      "         [[ 0.9115, -0.3325, -1.6416, -0.0372],\n",
      "          [ 0.1583,  0.1176, -1.2712,  0.2769],\n",
      "          [-0.2709, -0.9468,  0.1267, -0.7008],\n",
      "          [ 1.0967, -0.6246,  1.0002, -1.4664]]]])\n",
      "\n",
      "Output Tensor (Element-wise Square): tensor([[[[7.5476e-02, 1.0646e-03, 9.1935e-01, 1.1879e+00],\n",
      "          [8.5474e-01, 2.9412e-01, 2.7054e+00, 3.7103e-02],\n",
      "          [5.9877e-01, 5.3626e-02, 9.7074e-01, 2.5696e+00],\n",
      "          [3.0169e-01, 5.9526e-02, 5.8741e+00, 1.8187e-01]],\n",
      "\n",
      "         [[1.3198e-02, 2.7317e+00, 2.0399e-02, 5.3450e+00],\n",
      "          [7.9811e-04, 1.0241e+00, 1.1085e+00, 2.5252e-03],\n",
      "          [3.1793e-01, 9.9526e-01, 2.0207e-01, 4.4835e-01],\n",
      "          [8.3227e-01, 7.8121e-01, 5.1983e-02, 1.9596e+00]],\n",
      "\n",
      "         [[8.3090e-01, 1.1058e-01, 2.6949e+00, 1.3809e-03],\n",
      "          [2.5069e-02, 1.3827e-02, 1.6160e+00, 7.6665e-02],\n",
      "          [7.3361e-02, 8.9647e-01, 1.6057e-02, 4.9117e-01],\n",
      "          [1.2027e+00, 3.9014e-01, 1.0005e+00, 2.1503e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Define the CustomLayer class that performs and outputs the elementwise square function on the inputs\n",
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.square(x)\n",
    "\n",
    "# 2. Instantiate the CustomLayer\n",
    "custom_layer = CustomLayer()\n",
    "print(custom_layer)\n",
    "\n",
    "# 3. Generate a random input tensor\n",
    "input = torch.randn(1, 3, 4, 4)\n",
    "\n",
    "# 4. Apply the CustomLayer to the input tensor\n",
    "output = custom_layer(input)\n",
    "# 5. Print the input tensor and the resulting output tensor\n",
    "print(\"Input Tensor:\", input)\n",
    "print(\"\\nOutput Tensor (Element-wise Square):\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Behavior Cloning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name implies, Behavior Cloning is a machine learning technique where an **agent** learns to mimic the behavior of an **expert**. Hence, we (the agent) aim to clone the behavior of another agent which already peforms well on the task at hand. For a better intuition, we recommend this [Introduction into Behavior Cloning](https://www.youtube.com/watch?v=GIxDtuaC3To). Our task is the [MinAtar Breakout](https://github.com/kenjyoung/MinAtar), a game where a player controls a paddle to bounce a ball and break bricks.\n",
    "\n",
    "Therefore, we provide expert behavior in form of observation-acion pairs retrived by a well-trained policy. Your exercise will be to implement and train a simple neural network in PyTorch, that is able to aimitate the behavior of the expert and perform well on the task.\n",
    "\n",
    "We do the following steps:\n",
    "1. Load the Minatar breakout datasets\n",
    "2. Define a Convolutional Neural Network (CNN)\n",
    "3. Define a loss function\n",
    "4. Train the network on training data\n",
    "5. Test the network on test data\n",
    "\n",
    "\n",
    "<img src=\"breakout.gif\" alt=\"MinAtar\" width=\"20%\"/>\n",
    "\n",
    "_Agent using random actions to play MinAtar Breakout_  \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Loading data**\n",
    "\n",
    "When working with image, text, audio, or video data, you can use standard Python packages to load the data into a NumPy array, which can then be transformed into a ``torch.*Tensor``. However, for large datasets, computing gradients for all data points simultaneously isn't feasible. Therefore, we adopt a technique called **batching**, where the neural network is fed chunks of our data at a time. PyTorch offers the DataLoader class for efficient management of batching and data loading. By providing the ``DataLoader`` with the data and batch size, we obtain an iterable object that can be used for training or testing. It's a good practice to shuffle the data inside the loader to reduce biases during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 100000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load observations and actions\n",
    "with open('dataset.npy', 'rb') as f:\n",
    "    obss = np.load(f)\n",
    "    acts = np.load(f)\n",
    "\n",
    "# Convert to torch tensors\n",
    "obss = torch.from_numpy(obss).float() # PyTorch requires float or double dtype, not bool\n",
    "acts = torch.from_numpy(acts)\n",
    "\n",
    "# Create dataset and dataloaders, which we can iterate over\n",
    "dataset = []\n",
    "for i in range(len(obss)):\n",
    "    dataset.append((obss[i], acts[i]))\n",
    "\n",
    "# Do a 80% / 20% split between train and test set\n",
    "train_loader = DataLoader(dataset[:int(4*len(obss)/5)], batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(dataset[int(4*len(obss)/5):], batch_size=128, shuffle=True)\n",
    "\n",
    "print(f\"Size of dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we take a look at the samples of the dataset. Each sample consists of an observation paired with the corresponding action our agent should take. The observation is an image capturing the current game frame encoded as a NumPy array. As for the actions, they are represented by integers, where 0 describes \"DO NOTHING,\" 1 = \"MOVE LEFT,\" and 2 = \"MOVE RIGHT\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation is represented as Tensor with shape of torch.Size([10, 10, 4]). The first and second dimensions correspond to the height and width, while the third dimension describes the different game objects.\n",
      "Additionally, the data type (dtype) of the observation is torch.float32. Each value in the array indicates whether a particular object is present (1.0 = True) or not present (0.0 = False).\n",
      "The current action is 1 = MOVE LEFT\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get some arbitrary sample\n",
    "obs, act = dataset[10]\n",
    "\n",
    "# Actions and their meaning\n",
    "ACTIONS = {\n",
    "    0: \"DO NOTHING\",\n",
    "    1: \"MOVE LEFT\",\n",
    "    2: \"MOVE RIGHT\",\n",
    "}\n",
    "\n",
    "def to_rgb(obs):\n",
    "    \"\"\" Converts the observation into an rgb image. Taken from MinAtar. \"\"\"\n",
    "    obs = obs.bool().numpy()\n",
    "    n_channels = obs.shape[-1]\n",
    "    cmap = sns.color_palette(\"cubehelix\", n_channels)\n",
    "    cmap.insert(0, (0,0,0))\n",
    "    numerical_state = np.amax(obs * np.reshape(np.arange(n_channels) + 1, (1,1,-1)), 2)\n",
    "    rgb_array = np.stack(cmap)[numerical_state]\n",
    "    return rgb_array\n",
    "\n",
    "print(f\"The observation is represented as {obs.__class__.__name__} with shape of {obs.shape}. The first and second dimensions correspond to the height and width, while the third dimension describes the different game objects.\")\n",
    "print(f\"Additionally, the data type (dtype) of the observation is {obs.dtype}. Each value in the array indicates whether a particular object is present (1.0 = True) or not present (0.0 = False).\")\n",
    "print(f\"The current action is {act} = {ACTIONS[act.item()]}\")\n",
    "\n",
    "# Render observation\n",
    "img = to_rgb(obs)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Define Convolutional Neural Network**\n",
    "\n",
    "Here we define our own classifier that takes as input a batch of observations, and ouputs three logits for each observation. These logits can be fed into a softmax function later to obtain probabilities for the actions. However, it is more convenient for the ``CrossEntropyLoss`` used in classifiers to retrieve the raw logits. We want our model to have two convolutional layers followed by two linear layers. Each but the last layer should be followed by a Rectified Linear Unit (ReLU) activation function.\n",
    "\n",
    "Build a neural network, similar as in 1.3. Notice: it has to take as input 4-channel images. Also, we want the convolutional layers to output the same image height and width and therefore use a stride of one. However, because the kernel size is >1, padding around the images is needed. Visualize to yourself how the kernel size is leading to a change of output size and what padding is needed to keep the dimensions constant. See the PyTorch documentation for convolutional layers to get hints for the padding argument.\n",
    "\n",
    "<img src=\"padding.gif\" alt=\"MinAtar\" width=\"50%\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Defining a CNN**\n",
    "\n",
    "Fill in the gaps in the following code.\n",
    "\n",
    "1. Define the first convolutional layer with 3 input channels (given by the data) and 16 output channels, stride 1, and kernel size 3.\n",
    "    \n",
    "    Tipp: Apply padding, such that the image dimensions stay the same\n",
    "\n",
    "2. Define the second convolutional layer with 32 output channels, stride 1, and kernel size 3.\n",
    "\n",
    "    Tipp: Apply padding, such that the image dimensions stay the same\n",
    "\n",
    "3. Define the first linear layer mapping from the flattened output of convolutional layer 2, to 128 output nodes.\n",
    "\n",
    "    Tipp: How can the input nodes be retrieved by the ouput channels of convolutional layer 2 and the input data shape?\n",
    "\n",
    "4. Define the last linear layer\n",
    "\n",
    "    Tipp: How many output nodes do we need given the action space?\n",
    "\n",
    "5. Define the forward pass function by putting all the layers together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, obs_shape):\n",
    "        # obs_shape is the shape of a single observation -> use this information to define the dimensions of the layers\n",
    "        super(CNN, self).__init__()\n",
    "        height, width, channels  = obs_shape\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=channels, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)        \n",
    "    \n",
    "        self.fc1 = nn.Linear(32 * height * width, 128)\n",
    "        # We need 3 output nodes because we have 3 possible actions\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = CNN(obs_shape=obss.shape[1:])\n",
    "if torch.cuda.is_available():\n",
    "    net.to('cuda')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Define loss function and optimizer**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Defining a loss function**\\\n",
    "Implement a cross entropy loss function\n",
    "\n",
    "Hint: check out the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Defining an optimizer**\\\n",
    "Implement an adam optimizer and pass the learning rate as argument\n",
    "\n",
    "Hint: check out the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Train network**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Training the CNN**\\\n",
    "Fill in the gaps in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | loss: 0.007088 | accuracy:  0.56\n",
      "2 | loss: 0.005874 | accuracy:  0.67\n",
      "3 | loss: 0.005350 | accuracy:  0.70\n",
      "4 | loss: 0.005115 | accuracy:  0.72\n",
      "5 | loss: 0.004949 | accuracy:  0.72\n",
      "6 | loss: 0.004845 | accuracy:  0.73\n",
      "7 | loss: 0.004761 | accuracy:  0.74\n",
      "8 | loss: 0.004711 | accuracy:  0.74\n",
      "9 | loss: 0.004655 | accuracy:  0.74\n",
      "10 | loss: 0.004609 | accuracy:  0.75\n",
      "11 | loss: 0.004582 | accuracy:  0.75\n",
      "12 | loss: 0.004536 | accuracy:  0.75\n",
      "13 | loss: 0.004519 | accuracy:  0.75\n",
      "14 | loss: 0.004479 | accuracy:  0.75\n",
      "15 | loss: 0.004457 | accuracy:  0.75\n",
      "16 | loss: 0.004434 | accuracy:  0.76\n",
      "17 | loss: 0.004408 | accuracy:  0.76\n",
      "18 | loss: 0.004395 | accuracy:  0.76\n",
      "19 | loss: 0.004378 | accuracy:  0.76\n",
      "20 | loss: 0.004356 | accuracy:  0.76\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "acc_hist = []\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # perform the forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # calculate the loss ussing the criterion\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # perform the backward pass to compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the model's parameters using the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'{epoch + 1} | loss: {running_loss / total:.6f} | accuracy:  {correct/total:.2f}')\n",
    "    \n",
    "    loss_hist.append(running_loss / total)\n",
    "    acc_hist.append(correct/total)\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Plotting the training results**\\\n",
    "Plot the accuracy and loss over training steps. Make sure to give meaningful axes labels. If you are not familiar with ``matplotlib``, see this [quick start guide](https://matplotlib.org/stable/users/explain/quick_start.html#quick-start)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACEK0lEQVR4nO3dd3gUZdfA4d+mbQqkQHqAECD0aiCRJiqRgAgEkSZKKC8gBBDRF0XpKqGDFMFGU3oR6S2AfnSld+k9oSaBAAkkz/fHvFlYUkhI2ZRzX9dc2Z15ZvbMsOzs2afplFIKIYQQQgghhMgEM1MHIIQQQgghhMj7JLEQQgghhBBCZJokFkIIIYQQQohMk8RCCCGEEEIIkWmSWAghhBBCCCEyTRILIYQQQgghRKZJYiGEEEIIIYTINEkshBBCCCGEEJkmiYUQQgghhBAi0ySxKGA6depEyZIlX2rfYcOGodPpsjYgIfKYbdu2odPpWLp0qalDESLPk3uSyAuS3mu3bt0ydSi5niQWuYROp0vXsm3bNlOHanJt2rRBp9Px+eefmzoUIYTIl+SelLZOnTpRqFAhU4chRK5jYeoAhObXX381ej537lw2bdqUbH2FChUy9To//fQTiYmJL7XvoEGD+OKLLzL1+pkVExPDqlWrKFmyJAsWLGDUqFHyi5UQQmQxuScJIV6GJBa5xAcffGD0fPfu3WzatCnZ+uc9ePAAW1vbdL+OpaXlS8UHYGFhgYWFad8yy5YtIyEhgZkzZ/Lmm2/y119/0aBBA5PGlBKlFI8ePcLGxsbUoeRKsbGx2NnZmToMIUQq5J4kspp87hcM0hQqD3n99depXLky+/bt47XXXsPW1pYvv/wSgD/++IOmTZvi6emJXq+ndOnSfP311yQkJBgd4/n2rBcuXECn0zFu3Dh+/PFHSpcujV6vp1atWvz9999G+6bUnlWn09G7d29WrFhB5cqV0ev1VKpUifXr1yeLf9u2bdSsWRNra2tKly7NDz/8kOE2svPmzeOtt97ijTfeoEKFCsybNy/FcidPnqRNmza4uLhgY2NDuXLl+Oqrr4zKXL16la5duxqumY+PDz179iQ+Pj7V8wWYPXs2Op2OCxcuGNaVLFmSd955hw0bNlCzZk1sbGz44YcfAJg1axZvvvkmrq6u6PV6KlasyPTp01OMe926dTRo0IDChQtjb29PrVq1mD9/PgBDhw7F0tKSmzdvJtuve/fuODo68ujRozSv35YtW6hfvz52dnY4OjrSokULTpw4Ydi+dOlSdDodf/75Z7J9f/jhB3Q6HUePHjWsO3nyJO+99x5FihTB2tqamjVrsnLlyhSv159//kmvXr1wdXWlWLFiacYZFxfH0KFDKVOmDHq9nuLFizNgwADi4uKMyiW9/+bNm0e5cuWwtrbGz8+Pv/76K9kxDxw4QJMmTbC3t6dQoUI0bNiQ3bt3JysXFRXFJ598QsmSJdHr9RQrVoyOHTsma1ubmJjIt99+S7FixbC2tqZhw4acOXPGqMzp06dp1aoV7u7uWFtbU6xYMdq1a0d0dHSa5y9EXiD3pBdbsmQJfn5+2NjY4OzszAcffMDVq1eNykRERNC5c2eKFSuGXq/Hw8ODFi1aGN1j/vnnH4KCgnB2dsbGxgYfHx+6dOmSrhi+//57KlWqhF6vx9PTk9DQUKKiogzbe/fuTaFChXjw4EGyfdu3b4+7u7vRv9u6desM95HChQvTtGlTjh07ZrRfUlOxs2fP8vbbb1O4cGE6dOiQZpxXr16lS5cuuLm5Gf7dZs6caVQmqY/bokWL+PLLL3F3d8fOzo7mzZtz+fLlZMdMz/WH9H1nAO3+0KlTJxwdHXFwcKBz587JrtumTZuoV68ejo6OFCpUiHLlyhn+XxQEkurnMbdv36ZJkya0a9eODz74ADc3N0D78laoUCH69+9PoUKF2LJlC0OGDCEmJoaxY8e+8Ljz58/n3r179OjRA51Ox5gxY3j33Xc5d+7cC39R2r59O8uXL6dXr14ULlyYyZMn06pVKy5dukTRokUB7Utd48aN8fDwYPjw4SQkJDBixAhcXFzSfe7Xrl1j69atzJkzB9A+8CZOnMjUqVOxsrIylDt8+DD169fH0tKS7t27U7JkSc6ePcuqVav49ttvDcfy9/cnKiqK7t27U758ea5evcrSpUt58OCB0fHS69SpU7Rv354ePXrQrVs3ypUrB8D06dOpVKkSzZs3x8LCglWrVtGrVy8SExMJDQ017D979my6dOlCpUqVGDhwII6Ojhw4cID169fz/vvv8+GHHzJixAgWLVpE7969DfvFx8ezdOlSWrVqhbW1darxbd68mSZNmlCqVCmGDRvGw4cPmTJlCnXr1mX//v2ULFmSpk2bUqhQIRYvXpysJmjRokVUqlSJypUrA3Ds2DHq1q2Ll5cXX3zxBXZ2dixevJjg4GCWLVtGy5Ytjfbv1asXLi4uDBkyhNjY2FTjTExMpHnz5mzfvp3u3btToUIFjhw5wsSJE/n3339ZsWKFUfk///yTRYsW0bdvX/R6Pd9//z2NGzdm7969RrHWr18fe3t7BgwYgKWlJT/88AOvv/46f/75JwEBAQDcv3+f+vXrc+LECbp06cIrr7zCrVu3WLlyJVeuXMHZ2dnwuqNGjcLMzIzPPvuM6OhoxowZQ4cOHdizZ4/h3yUoKIi4uDj69OmDu7s7V69eZfXq1URFReHg4JDqNRAiryjI96QXmT17Np07d6ZWrVqEhYURGRnJd999x44dOzhw4ACOjo4AtGrVimPHjtGnTx9KlizJjRs32LRpE5cuXTI8b9SoES4uLnzxxRc4Ojpy4cIFli9f/sIYhg0bxvDhwwkMDKRnz56cOnWK6dOn8/fff7Njxw4sLS1p27Yt06ZNY82aNbRu3dqw74MHD1i1ahWdOnXC3Nwc0JrIhYSEEBQUxOjRo3nw4AHTp0+nXr16HDhwwChJfPLkCUFBQdSrV49x48alWZMVGRnJq6++akgMXVxcWLduHV27diUmJoZ+/foZlf/2228NfS1v3LjBpEmTCAwM5ODBg4aWAum9/un5zpCkTZs2+Pj4EBYWxv79+/n5559xdXVl9OjRgHaveeedd6hatSojRoxAr9dz5swZduzY8cJ/q3xDiVwpNDRUPf/P06BBAwWoGTNmJCv/4MGDZOt69OihbG1t1aNHjwzrQkJClLe3t+H5+fPnFaCKFi2q7ty5Y1j/xx9/KECtWrXKsG7o0KHJYgKUlZWVOnPmjGHdoUOHFKCmTJliWNesWTNla2urrl69alh3+vRpZWFhkeyYqRk3bpyysbFRMTExSiml/v33XwWo33//3ajca6+9pgoXLqwuXrxotD4xMdHwuGPHjsrMzEz9/fffyV4nqVxK56uUUrNmzVKAOn/+vGGdt7e3AtT69euTlU/p3yYoKEiVKlXK8DwqKkoVLlxYBQQEqIcPH6Yad+3atVVAQIDR9uXLlytAbd26NdnrPKt69erK1dVV3b5927Du0KFDyszMTHXs2NGwrn379srV1VU9efLEsO769evKzMxMjRgxwrCuYcOGqkqVKkbvr8TERFWnTh3l6+trWJd0verVq2d0zNT8+uuvyszMTP3f//2f0foZM2YoQO3YscOwDlCA+ueffwzrLl68qKytrVXLli0N64KDg5WVlZU6e/asYd21a9dU4cKF1WuvvWZYN2TIEAWo5cuXJ4sr6d9h69atClAVKlRQcXFxhu3fffedAtSRI0eUUkodOHBAAWrJkiUvPGchcju5JxkLCQlRdnZ2qW6Pj49Xrq6uqnLlykaf6atXr1aAGjJkiFJKqbt37ypAjR07NtVj/f777wpI8X6Vlhs3bigrKyvVqFEjlZCQYFg/depUBaiZM2cqpbTPNi8vL9WqVSuj/RcvXqwA9ddffymllLp3755ydHRU3bp1MyoXERGhHBwcjNaHhIQoQH3xxRfpirVr167Kw8ND3bp1y2h9u3btlIODg+H9lPT56+XlZfgu8Gys3333nVIq/ddfqfR9Z0h6r3Xp0sWoTMuWLVXRokUNzydOnKgAdfPmzXSdd34kTaHyGL1eT+fOnZOtf7Yt/71797h16xb169fnwYMHnDx58oXHbdu2LU5OTobn9evXB+DcuXMv3DcwMJDSpUsbnletWhV7e3vDvgkJCWzevJng4GA8PT0N5cqUKUOTJk1eePwk8+bNo2nTphQuXBgAX19f/Pz8jJpD3bx5k7/++osuXbpQokQJo/2TqrcTExNZsWIFzZo1o2bNmsle52WrwX18fAgKCkq2/tl/m+joaG7dukWDBg04d+6coUnMpk2buHfvHl988UWyWodn4+nYsSN79uzh7NmzhnXz5s2jePHiafY1uX79OgcPHqRTp04UKVLEsL5q1aq89dZbrF271rCubdu23Lhxw2i0l6VLl5KYmEjbtm0BuHPnDlu2bKFNmzaG99utW7e4ffs2QUFBnD59Oll1c7du3Qy/eqVlyZIlVKhQgfLlyxuOe+vWLd58800Atm7dalS+du3a+Pn5GZ6XKFGCFi1asGHDBhISEkhISGDjxo0EBwdTqlQpQzkPDw/ef/99tm/fTkxMDKD14alWrVqy2hZI/r7o3LmzUc3W8/9nkmokNmzYkGITAyHyg4J8T0rLP//8w40bN+jVq5fRZ3rTpk0pX748a9asAbTrZGVlxbZt27h7926Kx0r6ZX316tU8fvw43TFs3ryZ+Ph4+vXrh5nZ06973bp1w97e3hCDTqejdevWrF27lvv37xvKLVq0CC8vL+rVqwdo96moqCjat29v9Nlsbm5OQEBAss9mgJ49e74wTqUUy5Yto1mzZiiljI4dFBREdHQ0+/fvN9qnY8eOhu8CAO+99x4eHh6Ge1l6r396vjM866OPPjJ6Xr9+fW7fvm24hyT9W/3xxx8vPShBXieJRR7j5eWVYjOdY8eO0bJlSxwcHLC3t8fFxcXQyS497bmf/w+V9IGe2gddWvsm7Z+0740bN3j48CFlypRJVi6ldSk5ceIEBw4coG7dupw5c8awvP7666xevdrwnzrpxpHUBCYlN2/eJCYmJs0yL8PHxyfF9Tt27CAwMNDQr8HFxcXQ3jLp3yYpUXhRTG3btkWv1xuSqejoaFavXk2HDh3STIguXrwIYGie9awKFSpw69YtQ/Okxo0b4+DgwKJFiwxlFi1aRPXq1SlbtiwAZ86cQSnF4MGDcXFxMVqGDh0KaP/u6bk+zzt9+jTHjh1Ldtyk137+uL6+vsmOUbZsWR48eMDNmze5efMmDx48SPXcExMTDW1zz549m+73xYv+z/j4+NC/f39+/vlnnJ2dCQoKYtq0adK/QuQrBfWe9CJpfeaWL1/esF2v1zN69GjWrVuHm5sbr732GmPGjCEiIsJQvkGDBrRq1Yrhw4fj7OxMixYtmDVrVrI+Z+mNwcrKilKlShm2g3ZvefjwoaGP3P3791m7di2tW7c23FtOnz4NwJtvvpns83njxo3JPpstLCxe2J8OtHtyVFQUP/74Y7LjJiWtL/rc1+l0lClTxtAvJb3XPz3fGZ71ovdl27ZtqVu3Lv/5z39wc3OjXbt2LF68uEAlGdLHIo9JaZShqKgoGjRogL29PSNGjKB06dJYW1uzf/9+Pv/883S9oVP7JVkpla37ptdvv/0GwCeffMInn3ySbPuyZctS/NUsM1L7ov5858MkKf3bnD17loYNG1K+fHkmTJhA8eLFsbKyYu3atUycODHDHzZOTk688847zJs3jyFDhrB06VLi4uJeOFJLRuj1eoKDg/n999/5/vvviYyMZMeOHYwcOdJQJinuzz77LMVaGkh+g07vCFmJiYlUqVKFCRMmpLi9ePHi6TpOdkvP+378+PF06tSJP/74g40bN9K3b1/CwsLYvXt3um64QuR2BfWelJX69etHs2bNWLFiBRs2bGDw4MGEhYWxZcsWatSoYZiQc/fu3axatYoNGzbQpUsXxo8fz+7du7NkPo1XX32VkiVLsnjxYt5//31WrVrFw4cPDbXU8PRz/9dff8Xd3T3ZMZ4foUuv1xvVlKQm6bgffPABISEhKZapWrVqus8lO73ovWVjY8Nff/3F1q1bWbNmDevXr2fRokW8+eabbNy4MV219nmdJBb5wLZt27h9+zbLly/ntddeM6w/f/68CaN6ytXVFWtr62Qj5gAprnueUor58+fzxhtv0KtXr2Tbv/76a+bNm0fnzp0NTV2eHbnoeS4uLtjb26dZBp7+EhEVFWWo3gSMfuV5kVWrVhEXF8fKlSuNful4vso4qdr+6NGjL/zFrGPHjrRo0YK///6befPmUaNGDSpVqpTmPt7e3oDWwfx5J0+exNnZ2WgYwLZt2zJnzhzCw8M5ceIESimjG0zSdba0tCQwMDDN186o0qVLc+jQIRo2bJiuZmlJv6I9699//8XW1tbQEdPW1jbVczczMzMkK6VLl37h+yKjqlSpQpUqVRg0aBA7d+6kbt26zJgxg2+++SZLX0eI3CK/35PS49nP3KRmnElOnTpl2J6kdOnSfPrpp3z66aecPn2a6tWrM378eMOPaqB9+X/11Vf59ttvmT9/Ph06dGDhwoX85z//eWEMzzYDjY+P5/z588k+u9u0acN3331HTEwMixYtomTJkrz66qtGMYJ2/bLyc9/FxYXChQuTkJCQ7uM+/7mvlOLMmTOGBCS91z893xkyyszMjIYNG9KwYUMmTJjAyJEj+eqrr9i6dWuW3y9zI2kKlQ8kZcDP/hoTHx/P999/b6qQjJibmxMYGMiKFSu4du2aYf2ZM2dYt27dC/ffsWMHFy5coHPnzrz33nvJlrZt27J161auXbuGi4sLr732GjNnzuTSpUtGx0m6PmZmZgQHB7Nq1Sr++eefZK+XVC7pQ/TZoUtjY2MNo1Kl99yfPSZozQBmzZplVK5Ro0YULlyYsLCwZEPGPv8rW5MmTXB2dmb06NH8+eef6aqt8PDwoHr16syZM8domMGjR4+yceNG3n77baPygYGBFClShEWLFrFo0SL8/f2NmjK5urry+uuv88MPP3D9+vVkr5fSkLjp1aZNG65evcpPP/2UbNvDhw+TjSi1a9cuo/a3ly9f5o8//qBRo0aYm5tjbm5Oo0aN+OOPP4yGb4yMjGT+/PnUq1cPe3t7QBud5dChQ/z+++/JXjujv3bGxMTw5MkTo3VVqlTBzMzshU0YhMjL8vs9KT1q1qyJq6srM2bMMPr/vm7dOk6cOEHTpk0BbeSl5z/zS5cuTeHChQ373b17N9nnT/Xq1QHS/CwJDAzEysqKyZMnG+3/yy+/EB0dbYghSdu2bYmLi2POnDmsX7+eNm3aGG0PCgrC3t6ekSNHptjX42U/983NzWnVqhXLli1L8Qt+SsedO3cu9+7dMzxfunQp169fN/SRSe/1T893hoy4c+dOsnXp+bfKT6TGIh+oU6cOTk5OhISE0LdvX3Q6Hb/++muuqvYdNmwYGzdupG7duvTs2ZOEhASmTp1K5cqVOXjwYJr7zps3D3Nz82QfgkmaN2/OV199xcKFC+nfvz+TJ0+mXr16vPLKK3Tv3h0fHx8uXLjAmjVrDK81cuRINm7cSIMGDQxDml6/fp0lS5awfft2HB0dadSoESVKlKBr167897//xdzcnJkzZ+Li4pLsAyg1jRo1wsrKimbNmtGjRw/u37/PTz/9hKurq9EXcnt7eyZOnMh//vMfatWqxfvvv4+TkxOHDh3iwYMHRsmMpaUl7dq1Y+rUqZibm9O+fft0xTJ27FiaNGlC7dq16dq1q2G4WQcHB4YNG2ZU1tLSknfffZeFCxcSGxvLuHHjkh1v2rRp1KtXjypVqtCtWzdKlSpFZGQku3bt4sqVKxw6dChdcT3vww8/ZPHixXz00Uds3bqVunXrkpCQwMmTJ1m8eLFhrpAklStXJigoyGi4WYDhw4cbynzzzTeGscV79eqFhYUFP/zwA3FxcYwZM8ZQ7r///S9Lly6ldevWdOnSBT8/P+7cucPKlSuZMWMG1apVS/d5bNmyhd69e9O6dWvKli3LkydP+PXXXw03USHyq/x+T0ry+PHjFGseixQpQq9evRg9ejSdO3emQYMGtG/f3jDcacmSJQ1Nev/9918aNmxImzZtqFixIhYWFvz+++9ERkbSrl07AObMmcP3339Py5YtKV26NPfu3eOnn37C3t4+2Y9Cz3JxcWHgwIEMHz6cxo0b07x5c06dOsX3339PrVq1kv0o9corr1CmTBm++uor4uLijGqpQbtPTZ8+nQ8//JBXXnmFdu3aGe6Ha9asoW7dukydOjVd1+55o0aNYuvWrQQEBNCtWzcqVqzInTt32L9/P5s3b072hb1IkSLUq1ePzp07ExkZyaRJkyhTpgzdunUDtHtYeq4/kK7vDOk1YsQI/vrrL5o2bYq3tzc3btzg+++/p1ixYoZO8Plezg1AJTIitaH9KlWqlGL5HTt2qFdffVXZ2NgoT09PNWDAALVhw4Zkw5CmNrRfSkPdAWro0KGG56kN7RcaGppsX29vbxUSEmK0Ljw8XNWoUUNZWVmp0qVLq59//ll9+umnytraOpWroA0ZV7RoUVW/fv1UyyillI+Pj6pRo4bh+dGjR1XLli2Vo6Ojsra2VuXKlVODBw822ufixYuqY8eOysXFRen1elWqVCkVGhpqNITovn37VEBAgLKyslIlSpRQEyZMSHW42aZNm6YY28qVK1XVqlWVtbW1KlmypBo9erSaOXNmsmMkla1Tp46ysbFR9vb2yt/fXy1YsCDZMffu3asA1ahRozSvy/M2b96s6tatazh+s2bN1PHjx1Msu2nTJgUonU6nLl++nGKZs2fPqo4dOyp3d3dlaWmpvLy81DvvvKOWLl1qKJN0vTIyVGJ8fLwaPXq0qlSpktLr9crJyUn5+fmp4cOHq+joaEO5pPffb7/9pnx9fZVer1c1atRIcejd/fv3q6CgIFWoUCFla2ur3njjDbVz585k5W7fvq169+6tvLy8lJWVlSpWrJgKCQkxDIOYNNzh88PIJv1fmjVrllJKqXPnzqkuXbqo0qVLK2tra1WkSBH1xhtvqM2bN6f7OgiRW8g9yVjScKopLaVLlzaUW7RokapRo4bS6/WqSJEiqkOHDurKlSuG7bdu3VKhoaGqfPnyys7OTjk4OKiAgAC1ePFiQ5n9+/er9u3bqxIlSii9Xq9cXV3VO++8YzTMdlqmTp2qypcvrywtLZWbm5vq2bOnunv3boplv/rqKwWoMmXKpHq8rVu3qqCgIOXg4KCsra1V6dKlVadOnYziedFwvCmJjIxUoaGhqnjx4srS0lK5u7urhg0bqh9//NHotQG1YMECNXDgQOXq6qpsbGxU06ZNkw0Xq9SLr3+SF31nSHqvPT+M7PPfB8LDw1WLFi2Up6ensrKyUp6enqp9+/bq33//zdC1yMt0SuWinxBEgRMcHMyxY8dSbCcvUnfo0CGqV6/O3Llz+fDDD00djsnodDpCQ0Nf+lcyIYR4ltyTcrdt27bxxhtvsGTJEt577z1ThyNSIH0sRI55+PCh0fPTp0+zdu1aXn/9ddMElIf99NNPFCpUiHfffdfUoQghRJ4k9yQhsp70sRA5plSpUnTq1Mkwfvb06dOxsrJiwIABpg4tz1i1ahXHjx/nxx9/pHfv3kYjOQkhhEg/uScJkfUksRA5pnHjxixYsICIiAj0ej21a9dm5MiRKU5wJlLWp08fIiMjefvtt406JwshhMgYuScJkfWkj4UQQgghhBAi06SPhRBCCCGEECLTJLEQQgghhBBCZJr0sUhBYmIi165do3Dhwuh0OlOHI4QQmaKU4t69e3h6emJmJr8nZTe5hwgh8pOM3EMksUjBtWvXKF68uKnDEEKILHX58mWKFStm6jDyPbmHCCHyo/TcQySxSEHhwoUB7QLa29ubOBohhMicmJgYihcvbvhsE9lL7iFCiPwkI/cQSSxSkFR1bW9vLzcFIUS+Ic1ycobcQ4QQ+VF67iHS2FYIIYQQQgiRaZJYCCGEEEIIITJNEgshhBBCCCFEpkkfCyGEEEKIAiQhIYHHjx+bOgyRS1haWmJubp4lx5LEQgghhBCiAFBKERERQVRUlKlDEbmMo6Mj7u7umR7kQxILIYTIRo8ewY0bEBmpLTduwOPHYGOjLdbWTx+ntlhamvosRI7YtAn++Qfefx+8vU0djciHkpIKV1dXbG1tZaQ4gVKKBw8ecOPGDQA8PDwydTxJLIQQ+YJSEBsL0dHaEhPz9HFqz2NjtS/utrZgZ5exRamnyUJSwvDs86QlJibz52Zu/jTJqFMHVqzI/DFFLjR0KOzaBT4+kliILJeQkGBIKooWLWrqcEQuYmNjA8CNGzdwdXXNVLMoSSyEEHlGYiKcPQuHD8OhQ9py7Bjcvq19gU9MNHWEKbO0BDc3cHXV/lpZwcOHWm3Gw4cpL48ePd0/IQHu39eW6GjTnYfIZlWraonF4cPQrp2poxH5TFKfCltbWxNHInKjpPfF48ePJbEQQuQ/MTFw5MjTBOLwYe15bGza+5mbg4PD08XePvXntrbal/jY2JSXBw9S3wZPE4Xnl+fXOzpCRlscKKUlF88nH1ZWL3U5c6Vp06YxduxYIiIiqFatGlOmTMHf3z/V8kuWLGHw4MFcuHABX19fRo8ezdtvv23YrpRi6NCh/PTTT0RFRVG3bl2mT5+Or68vANu2beONN95I8dh79+6lVq1aABw+fJjQ0FD+/vtvXFxc6NOnDwMGDMjCM09F1ar8L4Dsfy1RYEnzJ5GSrHpfSGIhhMgRSml9C+LiID7e+G9cHJw5Y1wTcf58ysextobKlaFaNW2pUgXc3Z8mCzY2Gf8SnxvpdE+bPzk5mTqarLdo0SL69+/PjBkzCAgIYNKkSQQFBXHq1ClcXV2Tld+5cyft27cnLCyMd955h/nz5xMcHMz+/fupXLkyAGPGjGHy5MnMmTMHHx8fBg8eTFBQEMePH8fa2po6depw/fp1o+MOHjyY8PBwatasCUBMTAyNGjUiMDCQGTNmcOTIEbp06YKjoyPdu3fP3osiiYUQIq9TucDUqVOVt7e30uv1yt/fX+3ZsyfVsg0aNFBAsuXtt982lAkJCUm2PSgoKN3xREdHK0BFR0dn6ryEyK8SEpS6dEmpjRuVmjxZqdBQpRo2VKpyZaXKllXK21spDw+lihZVqlAhpayslNJSi4wtxYop1bSpUgMHKrVwoVInTij15Impzz7vyY2faf7+/io0NNTwPCEhQXl6eqqwsLAUy7dp00Y1bdrUaF1AQIDq0aOHUkqpxMRE5e7ursaOHWvYHhUVpfR6vVqwYEGKx4yPj1cuLi5qxIgRhnXff/+9cnJyUnFxcYZ1n3/+uSpXrly6z+2lr/fdu0/f/HfvZmxfIV7g4cOH6vjx4+rhw4emDiVX8Pb2VhMnTkx3+a1btypA3c3m/5uzZs1SDg4O2foaKUnr/ZGRzzST11hk9Fer5cuXEx8fb3h++/ZtqlWrRuvWrY3KNW7cmFmzZhme6/X67DsJIfKpBw/g33/h5Ek4derp31OntG2ZYW4Oer3WtMfKCooVe1oLkVQTIf0L86f4+Hj27dvHwIEDDevMzMwIDAxk165dKe6za9cu+vfvb7QuKCiIFf/ryX7+/HkiIiIIDAw0bHdwcCAgIIBdu3bRLoU+CytXruT27dt07tzZ6HVee+01rJ5pcxYUFMTo0aO5e/cuTtlZfeToCCVKwKVLWru/+vWz77WEyCNe1ERn6NChDBs2LMPH/fvvv7Gzs0t3+aQaTwcHhwy/VkFi8sRiwoQJdOvWzfDBPmPGDNasWcPMmTP54osvkpUvUqSI0fOFCxdia2ubLLHQ6/W4u7tnX+BC5FFKaW31b9+GO3ee/k16fP360yTi0qXUj2NhAWXKQPny2lKunJYcWFtriUJS0vD836Qli+biEXnQrVu3SEhIwM3NzWi9m5sbJ0+eTHGfiIiIFMtHREQYtietS63M83755ReCgoIoVqyY0ev4+PgkO0bStpQSi7i4OOLi4gzPYzIzFFjVqtp/vMOHJbEQAoyaLy5atIghQ4Zw6tQpw7pChQoZHiulSEhIwMLixV9vXVxcMhSHlZWVfK9MBzNTvnjSr1bP/sL0ol+tnvfLL7/Qrl27ZFnntm3bcHV1pVy5cvTs2ZPbt2+neoy4uDhiYmKMFiHymvh4OH4cfv8dxo6Fzz+H//wH3n0XGjTQagA8PbU2+3Z22g+j1atDw4bQujX06AFffglTpsDGjU+TiiJFtCFOu3SBMWPgjz+e1licOKG9XlgYdOoEgYFQrx74+2u1DhUqQKlSWsLh4vK0D4QkFcLUrly5woYNG+jatWumjxUWFoaDg4NhKV68+MsfTPpZCGHE3d3dsDg4OKDT6QzPT548SeHChVm3bh1+fn7o9Xq2b9/O2bNnadGiBW5ubhQqVIhatWqxefNmo+OWLFmSSZMmGZ7rdDp+/vlnWrZsia2tLb6+vqxcudKwfdu2beh0OsPkgrNnz8bR0ZENGzZQoUIFChUqROPGjY0SoSdPntC3b18cHR0pWrQon3/+OSEhIQQHB2foGkyfPp3SpUtjZWVFuXLl+PXXXw3blFIMGzaMEiVKoNfr8fT0pG/fvobt33//Pb6+vlhbW+Pm5sZ7772XodfOKJPWWLzMr1bP2rt3L0ePHuWXX34xWt+4cWPeffddfHx8OHv2LF9++SVNmjRh165dKQ6hFRYWxvDhwzN3MkLkAKXg5k3jZklJf8+f14YlTS8LCy1pKFrU+K+Li1b7UK6cVhPh7Jx95yMKJmdnZ8zNzYmMjDRaHxkZmeovgu7u7mmWT/obGRlpNMFTZGQk1atXT3a8WbNmUbRoUZo3b56u13n2NZ43cOBAo2ZaMTExL59cVKmi/ZXEQuQEpTLfrvVl2Npm6SgbX3zxBePGjaNUqVI4OTlx+fJl3n77bb799lv0ej1z586lWbNmnDp1ihIlSqR6nOHDhzNmzBjGjh3LlClT6NChAxcvXkzWWibJgwcPGDduHL/++itmZmZ88MEHfPbZZ8ybNw+A0aNHM2/ePGbNmkWFChX47rvvWLFiRaqj06Xk999/5+OPP2bSpEkEBgayevVqOnfuTLFixXjjjTdYtmwZEydOZOHChVSqVImIiAgOHToEwD///EPfvn359ddfqVOnDnfu3OH//u//MnBlX0LWd/9Iv6tXrypA7dy502j9f//7X+Xv7//C/bt3766qVKnywnJnz55VgNq8eXOK2x89eqSio6MNy+XLl3NdR0dRsMTEKHX0qFLLlysVFqZUSIhSr76qlJNT2p2dCxVSys9PqfbtlfrkE6W+/lqp77/XOj5v3KjUvn1KnT+vHT8x0dRnKXJKbu283bt3b8PzhIQE5eXllWbn7XfeecdoXe3atZN13h43bpxhe3R0dIqdtxMTE5WPj4/69NNPk71OUuft+Ph4w7qBAwfmTOdtpZQ6duzpf+aEhIzvL0QqUuyce//+y42skdnl/v2XOofnOzYndahesWLFC/etVKmSmjJliuH58523ATVo0KBnLs19Bah169YZvVZS5+1Zs2YpQJ05c8awz7Rp05Sbm5vhuZubm9GAEk+ePFElSpRQLVq0SPc51qlTR3Xr1s2oTOvWrQ2DFo0fP16VLVvW6DMrybJly5S9vb2KiYlJ9fWS5IvO2y/zq1WS2NhYFi5cyIgRI174OqVKlcLZ2ZkzZ87QsGHDZNv1er107hY5Jj4erl6Fy5e15kZJf599nNYkaDqdNinvs7UKSX89PPLHUKsi/+vfvz8hISHUrFkTf39/Jk2aRGxsrKG/XceOHfHy8iIsLAyAjz/+mAYNGjB+/HiaNm3KwoUL+eeff/jxxx8BrRlDv379+Oabb/D19TUMN+vp6Zms2cGWLVs4f/48//nPf5LF9f777zN8+HC6du3K559/ztGjR/nuu++YOHFi9l6QJGXLap2Q7t+HCxe0toRCiDQlDRed5P79+wwbNow1a9Zw/fp1njx5wsOHD7mUVsdBoGpSU0TAzs4Oe3t7bty4kWp5W1tbSpcubXju4eFhKB8dHU1kZKTR3Dzm5ub4+fmRmIHZXE+cOJFsqOu6devy3XffAdC6dWsmTZpEqVKlaNy4MW+//TbNmjXDwsKCt956C29vb8O2xo0bG5p6ZReTJhZWVlb4+fkRHh5u+OBPTEwkPDyc3r17p7nvkiVLiIuL44MPPnjh61y5coXbt28bVY8LkR2Ugrt34eLFp8vzSUNEhFbuRRwdoXTpp4lDUvLg66v1UxAiL2vbti03b95kyJAhREREUL16ddavX29oGnvp0iXMzJ52A6xTpw7z589n0KBBfPnll/j6+rJixQrDHBYAAwYMIDY2lu7duxMVFUW9evVYv3491tbWRq/9yy+/UKdOHcqXL58sLgcHBzZu3EhoaCh+fn44OzszZMiQ7J/DIomFBVSqBAcOaM2hJLEQ2cnWVktiTfG6Wej5frafffYZmzZtYty4cZQpUwYbGxvee+89o1FFU2JpaWn0XKfTpZkEpFRepecGn4WKFy/OqVOn2Lx5M5s2baJXr16MHTuWP//8k8KFC7N//362bdvGxo0bGTJkCMOGDePvv//G0dExW+Ix+ahQGf3VKskvv/xCcHAwRZ8bj/L+/fsMHz6cVq1a4e7uztmzZxkwYABlypQhKCgox85L5E+JiRAZaZw4PLtcuJC+z2i9HooX15YSJVL+W7hwtp+OECbVu3fvVH9E2rZtW7J1rVu3TjYC4LN0Oh0jRox4YU32/Pnz09xetWrV7G+HnHYATxOLDHbyFCJDdDptNI98ZseOHXTq1ImWLVsC2nfDCxcu5GgMDg4OuLm58ffff/Paa68BkJCQwP79+1Ps95WaChUqsGPHDkJCQgzrduzYQcWKFQ3PbWxsaNasGc2aNSM0NJTy5ctz5MgRXnnlFSwsLAgMDCQwMJChQ4fi6OjIli1bePfdd7PsXJ9l8sQio79aAZw6dYrt27ezcePGZMczNzfn8OHDzJkzh6ioKDw9PWnUqBFff/21NHcS6Xb/Phw7pt3XDx/WOkgn1T48M6pkqlxcoGRJrclSiRJPl6TEwcVFmiwJIVKR1IH7yBHTxiFEHuXr68vy5ctp1qwZOp2OwYMHZ6j5UVbp06cPYWFhlClThvLlyzNlyhTu3r37wrk5nvXf//6XNm3aUKNGDQIDA1m1ahXLly83jHI1e/ZsEhISCAgIwNbWlt9++w0bGxu8vb1ZvXo1586d47XXXsPJyYm1a9eSmJhIuXLlsuuUTZ9YQMZ/tSpXrlyqVU02NjZs2LAhK8MT+VhiIpw79zSBSFrOnk19HzMz8PLSkoaUlhIlsryWVwhRkMiQs0JkyoQJE+jSpQt16tTB2dmZzz//3CRTCXz++edERETQsWNHzM3N6d69O0FBQSmOUJqa4OBgvvvuO8aNG8fHH3+Mj48Ps2bN4vXXXwfA0dGRUaNG0b9/fxISEqhSpQqrVq2iaNGiODo6snz5coYNG8ajR4/w9fVlwYIFVKpUKZvOGHQqpxuD5QExMTE4ODgQHR2Nvb29qcMRWeTOHe0HwGcTiKNHUx9pz8NDu79XrQoVK4KPj5Y4eHnBc80qhcjV5DMtZ2X6ekdGgru7Vq15/778UiGyxKNHjzh//jw+Pj7J+h2JnJGYmEiFChVo06YNX3/9tanDMZLW+yMjn2m5osZCiMxI6jB95Uray717Ke9vba31lUxKIqpW1VoiZHBSTiGEyBpubuDqCjduaG0ya9UydURCiJdw8eJFNm7cSIMGDYiLi2Pq1KmcP3+e999/39ShZRtJLESeERUFy5fDmTPJk4aHD9N3DG9v4wSialUoU0YbiEUIIXKNKlUgPFyrWpXEQog8yczMjNmzZ/PZZ5+hlKJy5cps3ryZChUqmDq0bCNfp0Sud/w4TJ0Kc+dCbGzq5VxctGZKxYqlvHh5QaFCORe3EEK8tKpVtcRCOnALkWcVL16cHTt2mDqMHCWJhciVEhJgzRqYMgX+N/ABAJUrw5tvJk8gPD21Jk1CCJEvSAduIUQeJImFyFXu3oWZM2HaNDh/XltnZgYtWkDfvtCggQzTKoQoAJ5NLJSSDz4hRJ4giYXIFY4f12on5s59OkqTkxN06wa9eml9I4QQosCoWFH7VeX2bbh+XauWFSILmGI+B5H7ZdX7QhILYTIJCbB6tZZQhIc/XV+lilY78f77MsqiEKKAsraGsmW12TmPHJHEQmSalZUVZmZmXLt2DRcXF6ysrDI0UZvIn5RSxMfHc/PmTczMzLCyssrU8SSxEDnu7l345RetudOFC9o6MzMIDtYSitdek1p/IYSgalUtsTh8GIKCTB2NyOPMzMzw8fHh+vXrXLt2zdThiFzG1taWEiVKYGZmlqnjSGIhcsz16zB+PMyY8XR0pyJFtOZOPXtKcychhDBStSosXiwduEWWsbKyokSJEjx58oSEhARThyNyCXNzcywsLLKkBksSC5HtLlyAMWO0Ttlxcdq6KlXg44+15k42NiYNTwghcicZGUpkA51Oh6WlJZaWlqYOReRDkliIbHPyJISFwbx5Wn8KgDp14KuvoEkTae4khBBpqlJF+3viBDx+DPJFUAiRy2WuIZUQKThwAFq31gY1mTtXSyreegu2bYPt2+HttyWpEEKIF/L2hsKFtaTi1ClTRyOEEC8kiYXIMjt2aEnDK6/A0qXa0OvBwbB3L2zcKHNQCCFEhuh00hxKCJGnSGIhMkUp2LQJXn8d6tWDdeu0EZ46dNBGSPz9d6hVy9RRCiFEHiWJhRAiD5E+FuKlJCbCypUwciT8/be2ztISOnWCzz+H0qVNGp4QQuQPklgIIfIQSSxEhm3bBv37a30pQBvVqUcP+PRTKFbMpKEJIUT+ktSB+8gR08YhhBDpIImFSLezZ+G//9WaNwHY20Pv3tCvH7i4mDQ0IYTInypX1v5euQJ37miT/wghRC4lfSzEC0VHawlFhQpaUmFuDqGhWqLx7beSVAghRLZxcICSJbXHUmshhMjlJLEQqXryRJslu0wZGDdOG/GwcWOtqe/UqeDsbOoIhRCiAJB+FkKIPEISC5GiTZugenXo2RNu3dJqK9au1UZ9qljR1NEJIUQBIv0shBB5hCQWwsjJk/DOO9CoERw7pjXnnTIFDh3SZssWQoisMm3aNEqWLIm1tTUBAQHs3bs3zfJLliyhfPnyWFtbU6VKFdauXWu0XSnFkCFD8PDwwMbGhsDAQE6fPp3sOGvWrCEgIAAbGxucnJwIDg422q7T6ZItCxcuzPT5vjSpsRBC5BGSWAhA6xP48cfaD2Nr1oCFhdYp+8wZrYO2paWpIxRC5CeLFi2if//+DB06lP3791OtWjWCgoK4ceNGiuV37txJ+/bt6dq1KwcOHCA4OJjg4GCOHj1qKDNmzBgmT57MjBkz2LNnD3Z2dgQFBfHo0SNDmWXLlvHhhx/SuXNnDh06xI4dO3j//feTvd6sWbO4fv26YXk++chRSYnFkSPaWN9CCJFL6ZRSytRB5DYxMTE4ODgQHR2Nvb29qcPJVo8fw/TpMGwY3L2rrWvWTOtTUbasSUMTQmSR3PiZFhAQQK1atZg6dSoAiYmJFC9enD59+vDFF18kK9+2bVtiY2NZvXq1Yd2rr75K9erVmTFjBkopPD09+fTTT/nss88AiI6Oxs3NjdmzZ9OuXTuePHlCyZIlGT58OF27dk01Np1Ox++///7SyUSWX+8nT6BwYXj0CE6f1jq+CSFEDsnIZ5rUWBRgu3ZpNRQff6wlFZUra30rVq6UpEIIkX3i4+PZt28fgYGBhnVmZmYEBgaya9euFPfZtWuXUXmAoKAgQ/nz588TERFhVMbBwYGAgABDmf3793P16lXMzMyoUaMGHh4eNGnSxKjWI0loaCjOzs74+/szc+ZMTPobnIUFVKqkPZbmUEKIXEwSiwIqPBwCA+HUKW242BkztAnvnrtvCyFElrt16xYJCQm4ubkZrXdzcyMiIiLFfSIiItIsn/Q3rTLnzp0DYNiwYQwaNIjVq1fj5OTE66+/zp07dwz7jBgxgsWLF7Np0yZatWpFr169mDJlSqrnExcXR0xMjNGS5aQDtxAiD5AJ8gqgdeugZUuIi9OGj124UBsqXQgh8rPE//VP+Oqrr2jVqhWg9aUoVqwYS5YsoUePHgAMHjzYsE+NGjWIjY1l7Nix9O3bN8XjhoWFMXz48OwNXjpwCyHyAKmxKGD++AOCg7WkonlzWLFCkgohRM5ydnbG3NycyMhIo/WRkZG4u7unuI+7u3ua5ZP+plXGw8MDgIrPjJmt1+spVaoUly5dSjXegIAArly5QlxcXIrbBw4cSHR0tGG5fPlyqsd6aZJYCCHyAEksCpAlS+C99yA+Hlq3hqVLQa83dVRCiILGysoKPz8/wsPDDesSExMJDw+ndu3aKe5Tu3Zto/IAmzZtMpT38fHB3d3dqExMTAx79uwxlPHz80Ov13Pq1ClDmcePH3PhwgW8vb1TjffgwYM4OTmhT+UDU6/XY29vb7RkuaTE4uxZiI3N+uMLIUQWkKZQBcRvv0FIiDZS4QcfwKxZWn9AIYQwhf79+xMSEkLNmjXx9/dn0qRJxMbG0rlzZwA6duyIl5cXYWFhAHz88cc0aNCA8ePH07RpUxYuXMg///zDjz/+CGgjOfXr149vvvkGX19ffHx8GDx4MJ6enobRnezt7fnoo48YOnQoxYsXx9vbm7FjxwLQunVrAFatWkVkZCSvvvoq1tbWbNq0iZEjRxpGmjIZFxdwc4PISG2SIX9/08YjhBApkK+WBcDPP0P37qAUdO0KP/wA5uamjkoIUZC1bduWmzdvMmTIECIiIqhevTrr1683dL6+dOkSZmZPK9Xr1KnD/PnzGTRoEF9++SW+vr6sWLGCypUrG8oMGDCA2NhYunfvTlRUFPXq1WP9+vVYW1sbyowdOxYLCws+/PBDHj58SEBAAFu2bMHJyQkAS0tLpk2bxieffIJSijJlyjBhwgS6deuWQ1cmDVWrakP3HT4siYUQIleSeSxSkBvHfH9Z06ZpE9wB9OqlzaJtJg3ghChQ8tNnWl6Qbdf7s89g/Hjo0wcmT8664wohRBpkHgsBwIQJT5OK/v1h6lRJKoQQIs+SDtxCiFxOvmbmU99+C59+qj3+8kttJm2dzrQxCSGEyIRnEwtpbCCEyIUkschnlILBg2HQIO35119rSYYkFUIIkcdVqKB1kLt7F65dM3U0QgiRTK5ILKZNm0bJkiWxtrYmICCAvXv3plr29ddfR6fTJVuaNm1qKKOUYsiQIXh4eGBjY0NgYCCnT5/OiVMxKaVgwAD45hvt+ZgxTxMMIYQQeZxeD+XKaY+lOZQQIhcyeWKxaNEi+vfvz9ChQ9m/fz/VqlUjKCiIGzdupFh++fLlXL9+3bAcPXoUc3Nzw1CBAGPGjGHy5MnMmDGDPXv2YGdnR1BQEI8ePcqp08pxiYnQt6/W5Am0fn3//a9pYxJCCJHFpJ+FECIXM3likTSMX+fOnalYsSIzZszA1taWmTNnpli+SJEiuLu7G5ZNmzZha2trSCyUUkyaNIlBgwbRokULqlatyty5c7l27RorVqzIwTPLOYmJ8NFHWudsnU4bTrZPH1NHJYQQIstJYiGEyMVMmljEx8ezb98+AgMDDevMzMwIDAxk165d6TrGL7/8Qrt27bCzswPg/PnzREREGB3TwcGBgICAdB8zL0lIgM6d4aeftBGfZs3S5qwQQgiRD1Wpov09csS0cQghRApMOkHerVu3SEhIMEyIlMTNzY2TJ0++cP+9e/dy9OhRfvnlF8O6iIgIwzGeP2bStufFxcURFxdneB4TE5PuczC1yZNh7lytP9+8edC2rakjEkIIkW2SaixOnID4eLCyMm08QgjxDJM3hcqMX375hSpVquCfyRlIw8LCcHBwMCzFixfPogizV1wcjB2rPf7uO0kqhBAi3yteHBwc4MkTSMcPcEIIkZNMmlg4Oztjbm5OZGSk0frIyEjc3d3T3Dc2NpaFCxfStWtXo/VJ+2XkmAMHDiQ6OtqwXL58OaOnYhJz5sD161CsGHTrZupohBBCZDudTvpZCCFyLZMmFlZWVvj5+REeHm5Yl5iYSHh4OLVr105z3yVLlhAXF8cHH3xgtN7Hxwd3d3ejY8bExLBnz55Uj6nX67G3tzdacrsnT7ThZEGbCE9qw4UQooCQxEIIkUuZtI8FQP/+/QkJCaFmzZr4+/szadIkYmNj6dy5MwAdO3bEy8uLsLAwo/1++eUXgoODKVq0qNF6nU5Hv379+Oabb/D19cXHx4fBgwfj6elJcHBwTp1Wtlu6FM6ehaJFpbZCCCEKFOnALYTIpUyeWLRt25abN28yZMgQIiIiqF69OuvXrzd0vr506RJmZsYVK6dOnWL79u1s3LgxxWMOGDCA2NhYunfvTlRUFPXq1WP9+vVYW1tn+/nkBKUgKc/q2xf+NyCWEEKIgkBqLIQQuZROKaVMHURuExMTg4ODA9HR0bmyWdSaNfDOO1CoEFy8CEWKmDoiIURults/0/KbbL/e9+5B0nFv3gRn56x/DSGE+J+MfKbl6VGhCqqk2oqPPpKkQgghCpzChaFUKe2xNIcSQuQikljkMf/3f7Bjh9ZZ+5NPTB2NEEIIk5B+FkKIXEgSizwmqbaiUyfw9DRpKEIIIUxF+lkIIXKhDCcWJUuWZMSIEVy6dCk74hFpOHgQ1q0DMzMYMMDU0QghhDAZSSyEELlQhhOLfv36sXz5ckqVKsVbb73FwoULiYuLy47YxHOSaivatIHSpU0bixBCCBNKSiyOHoWEBNPGIoQQ//NSicXBgwfZu3cvFSpUoE+fPnh4eNC7d2/279+fHTEK4PRpbe4KgIEDTRuLEEIIEytdGmxs4OFDbVIjIYTIBV66j8Urr7zC5MmTuXbtGkOHDuXnn3+mVq1aVK9enZkzZyKj2GatMWMgMRGaNn36Q5UQQogCytwcKlXSHksHbiFELvHSicXjx49ZvHgxzZs359NPP6VmzZr8/PPPtGrVii+//JIOHTpkZZwF2tWrMGeO9lhqK4QQQgDSz0IIketkeObt/fv3M2vWLBYsWICZmRkdO3Zk4sSJlC9f3lCmZcuW1KpVK0sDLcgmTIDHj6F+fahb19TRCCGEyBUksRBC5DIZrrGoVasWp0+fZvr06Vy9epVx48YZJRUAPj4+tGvXLsuCLMhu34YfftAeS22FECI/mTZtGiVLlsTa2pqAgAD27t2bZvklS5ZQvnx5rK2tqVKlCmvXrjXarpRiyJAheHh4YGNjQ2BgIKdPn052nDVr1hAQEICNjQ1OTk4EBwcbbb906RJNmzbF1tYWV1dX/vvf//LkyZNMn2+Wk8RCCJHLZDixOHfuHOvXr6d169ZYWlqmWMbOzo5Zs2ZlOjgBU6ZAbCxUrw6NG5s6GiGEyBqLFi2if//+DB06lP3791OtWjWCgoK4ceNGiuV37txJ+/bt6dq1KwcOHCA4OJjg4GCOHj1qKDNmzBgmT57MjBkz2LNnD3Z2dgQFBfHo0SNDmWXLlvHhhx/SuXNnDh06xI4dO3j//fcN2xMSEmjatCnx8fHs3LmTOXPmMHv2bIYMGZJ9F+NlJU2Sd+4c3L9v2liEEAJAZdDevXvV7t27k63fvXu3+vvvvzN6uFwpOjpaASo6Otqkcdy7p5STk1Kg1KJFJg1FCJGH5ZbPtGf5+/ur0NBQw/OEhATl6empwsLCUizfpk0b1bRpU6N1AQEBqkePHkoppRITE5W7u7saO3asYXtUVJTS6/VqwYIFSimlHj9+rLy8vNTPP/+calxr165VZmZmKiIiwrBu+vTpyt7eXsXFxaXr3HL0ent4aDeJXbuy/7WEEAVSRj7TMlxjERoayuXLl5Otv3r1KqGhoZlOdMRTP/4Id++Cry+0amXqaIQQImvEx8ezb98+AgMDDevMzMwIDAxk165dKe6za9cuo/IAQUFBhvLnz58nIiLCqIyDgwMBAQGGMvv37+fq1auYmZlRo0YNPDw8aNKkiVGtx65du6hSpQpubm5GrxMTE8OxY8cyf/JZTZpDCSFykQwnFsePH+eVV15Jtr5GjRocP348S4ISEBcH48drjwcM0EYWFEKI/ODWrVskJCQYfXkHcHNzIyIiIsV9IiIi0iyf9DetMufOnQNg2LBhDBo0iNWrV+Pk5MTrr7/OnTt30nydZ1/jeXFxccTExBgtOUYSCyFELpLhxEKv1xMZGZls/fXr17GwyPAgUyIVv/4K166Bpyd8+KGpoxFCiLwvMTERgK+++opWrVrh5+fHrFmz0Ol0LFmy5KWPGxYWhoODg2EpXrx4VoX8Ykn9LCSxEELkAhlOLBo1asTAgQOJjo42rIuKiuLLL7/krbfeytLgCqqEBG1CPIBPPwW93rTxCCFEVnJ2dsbc3DzZj1SRkZG4u7unuI+7u3ua5ZP+plXGw8MDgIoVKxq26/V6SpUqxaVLl9J8nWdf43lJ98SkJaXmwtkmqcbiyBGQiWmFECaW4cRi3LhxXL58GW9vb9544w3eeOMNfHx8iIiIYHxS2x2RKcuWwenTUKQIdO9u6miEECJrWVlZ4efnR3h4uGFdYmIi4eHh1K5dO8V9ateubVQeYNOmTYbyPj4+uLu7G5WJiYlhz549hjJ+fn7o9XpOnTplKPP48WMuXLiAt7e34XWOHDliNDrVpk2bsLe3N0pInqXX67G3tzdackz58mBhAVFRcOVKzr2uEEKkIMNtl7y8vDh8+DDz5s3j0KFD2NjY0LlzZ9q3b5/q8LMi/ZSCkSO1x337QqFCpo1HCCGyQ//+/QkJCaFmzZr4+/szadIkYmNj6dy5MwAdO3bEy8uLsLAwAD7++GMaNGjA+PHjadq0KQsXLuSff/7hxx9/BECn09GvXz+++eYbfH198fHxYfDgwXh6ehrmqbC3t+ejjz5i6NChFC9eHG9vb8aOHQtA69atAa1WvmLFinz44YeMGTOGiIgIBg0aRGhoKPrcWH2s12vJxdGjWnOonGyGJYQQz3mpThF2dnZ0l5/Ss8X69XDoENjZQZ8+po5GCCGyR9u2bbl58yZDhgwhIiKC6tWrs379ekNH6UuXLmFm9rRSvU6dOsyfP59Bgwbx5Zdf4uvry4oVK6hcubKhzIABA4iNjaV79+5ERUVRr1491q9fj7W1taHM2LFjsbCw4MMPP+Thw4cEBASwZcsWnJycADA3N2f16tX07NmT2rVrY2dnR0hICCNGjMihK/MSqlZ9mlg0bWrqaIQQBZhOqZdrlHn8+HEuXbpEfHy80frmzZtnSWCmFBMTg4ODA9HR0TlbpQ289hr83/9B//5PR4USQojMMOVnWkGU49d71CgYOBDat4f587P/9YQQBUpGPtMyXGNx7tw5WrZsyZEjR9DpdCTlJTqdDtBmLRUvZ8cOLamwtNQSCyGEEOKFZMhZIUQukeHO2x9//DE+Pj7cuHEDW1tbjh07xl9//UXNmjXZtm1bNoRYcPyvKTEhIeDlZdpYhBAiJZcvX+bKM52E9+7dS79+/Qx9HYQJJCUWJ0/Co0emjUUIUaBlOLHYtWsXI0aMwNnZGTMzM8zMzKhXrx5hYWH07ds3O2IsEA4dgjVrwMxMmxBPCCFyo/fff5+tW7cC2oRxb731Fnv37uWrr77K3f0Q8jMvL/Dw0MYqX7vW1NEIIQqwDCcWCQkJFC5cGNDGIr927RoA3t7eRkP4iYwZNUr727o1+PqaNhYhhEjN0aNH8ff3B2Dx4sVUrlyZnTt3Mm/ePGbPnm3a4AoqnQ66dNEef/+9aWMRQhRoGU4sKleuzKFDhwAICAhgzJgx7NixgxEjRlCqVKksD7AguHIFFi/WHn/xhWljEUKItDx+/Ngw7OrmzZsNA3aUL1+e69evmzK0gq17d63KOzxcaxIlhBAmkOHEYtCgQSQmJgIwYsQIzp8/T/369Vm7di2TJ0/O8gALgn37IDERqlfXFiGEyK0qVarEjBkz+L//+z82bdpE48aNAbh27RpFixY1cXQFWIkS0KyZ9nj6dNPGIoQosDKcWAQFBfHuu+8CUKZMGU6ePMmtW7e4ceMGb775ZpYHWBD8+6/2t3x508YhhBAvMnr0aH744Qdef/112rdvT7Vq1QBYuXKloYmUMJFevbS/s2dDbKxJQxFCFEwZGm728ePH2NjYcPDgQaNJiYoUKZLlgRUkp09rf8uWNW0cQgjxIq+//jq3bt0iJibGMKkcQPfu3bG1tTVhZILAQChTBs6c0eaz6NbN1BEJIQqYDNVYWFpaUqJECZmrIosl1VhIp20hRG738OFD4uLiDEnFxYsXmTRpEqdOncLV1dXE0RVwZmZPay2+/x5ebv5bIYR4aRluCvXVV1/x5ZdfcufOneyIp0BKSiykxkIIkdu1aNGCuXPnAhAVFUVAQADjx48nODiY6dK23/Q6dQIbGzh4EHbtMnU0QogCJsOJxdSpU/nrr7/w9PSkXLlyvPLKK0aLyJj79yFpIBWpsRBC5Hb79++nfv36ACxduhQ3NzcuXrzI3LlzZQCP3MDJCdq31x7L0LNCiByWoT4WAMHBwdkQRsGV1L/C2Vm7HwghRG724MEDw1xGGzdu5N1338XMzIxXX32Vixcvmjg6AWjNoWbOhCVLYMIEkCZqQogckuHEYujQodkRR4ElzaCEEHlJmTJlWLFiBS1btmTDhg188sknANy4cQN7e3sTRycA8PMDf3/Yu1dLMGSCJCFEDslwUyiRtWREKCFEXjJkyBA+++wzSpYsib+/P7Vr1wa02osaNWqYODphkNSJe8YMkAFXhBA5JMOJhZmZGebm5qkuImNkRCghRF7y3nvvcenSJf755x82bNhgWN+wYUMmTpxowsiEkbZtoUgRuHgR1q41dTRCiAIiw02hfv/9d6Pnjx8/5sCBA8yZM4fhw4dnWWAFhdRYCCHyGnd3d9zd3bly5QoAxYoVk8nxchtra+jaFcaO1TpxJ83KLYQQ2SjDNRYtWrQwWt577z2+/fZbxowZw8qVKzMcwLRp0yhZsiTW1tYEBASwd+/eNMtHRUURGhqKh4cHer2esmXLsvaZX2OGDRuGTqczWsrn4imtpcZCCJGXJCYmMmLECBwcHPD29sbb2xtHR0e+/vprEhMTTR2eeFaPHqDTwfr1cPasqaMRQhQAGa6xSM2rr75K9+7dM7TPokWL6N+/PzNmzCAgIIBJkyYRFBSU6kRL8fHxvPXWW7i6urJ06VK8vLy4ePEijo6ORuUqVarE5s2bDc8tLLLsNLPU7duQNB1ImTKmjUUIIdLjq6++4pdffmHUqFHUrVsXgO3btzNs2DAePXrEt99+a+IIhUHp0tC4Maxbp/W1GDvW1BEJIfK5LPnG/fDhQyZPnoyXl1eG9pswYQLdunWjc+fOAMyYMYM1a9Ywc+ZMvkhhFIuZM2dy584ddu7ciaWlJQAlS5ZMVs7CwgJ3d/eMn0gOS2oGVawY2NmZNhYhhEiPOXPm8PPPP9O8eXPDuqpVq+Ll5UWvXr0kschtevXSEouZM2HECG3yPCGEyCYZbgrl5OREkSJFDIuTkxOFCxdm5syZjM3AryHx8fHs27ePwMDAp8GYmREYGMiuVGYLXblyJbVr1yY0NBQ3NzcqV67MyJEjSXhuxIvTp0/j6elJqVKl6NChA5cuXcroaeYIaQYlhMhr7ty5k2Lz0vLly3MnqQpW5B5NmoC3t1Y9vmiRqaMRQuRzGa6xmDhxIjqdzvDczMwMFxcXAgICcMrADG+3bt0iISEBNzc3o/Vubm6cPHkyxX3OnTvHli1b6NChA2vXruXMmTP06tWLx48fG+bXCAgIYPbs2ZQrV47r168zfPhw6tevz9GjRw2TOj0vLi6OuLg4w/OYmJh0n0dmSMdtIUReU61aNaZOnZpslu2pU6dStWpVE0UlUmVuDj17anNZfP89dOpk6oiEEPlYhhOLTib8UEpMTMTV1ZUff/wRc3Nz/Pz8uHr1KmPHjjUkFk2aNDGUr1q1KgEBAXh7e7N48WK6du2a4nHDwsJMMqKV1FgIIfKaMWPG0LRpUzZv3myYw2LXrl1cvnzZaCANkYt06QJDhsDff2tLrVqmjkgIkU9luCnUrFmzWLJkSbL1S5YsYc6cOek+jrOzM+bm5kRGRhqtj4yMTLV/hIeHB2XLljWaL6NChQpEREQQHx+f4j6Ojo6ULVuWM2fOpBrLwIEDiY6ONiyXL19O93lkhsy6LYTIaxo0aMC///5Ly5YtiYqKIioqinfffZdjx47x66+/mjo8kRIXF2jTRns8fbppYxFC5GsZTizCwsJwdnZOtt7V1ZWRI0em+zhWVlb4+fkRHh5uWJeYmEh4eLjhV7Dn1a1blzNnzhgNafjvv//i4eGBlZVVivvcv3+fs2fP4uHhkWoser0ee3t7oyW7KSVNoYQQeZOnpyfffvsty5YtY9myZXzzzTfcvXuXX375JUPHyehw40uWLKF8+fJYW1tTpUqVZDUkSimGDBmCh4cHNjY2BAYGcjrpg/Z/SpYsmWxI8lGjRhm2X7hwIdl2nU7H7t27M3RuuU7STNwLFmhDEgohRDbIcGJx6dIlfHx8kq339vbOcCfp/v3789NPPzFnzhxOnDhBz549iY2NNYwS1bFjRwYOHGgo37NnT+7cucPHH3/Mv//+y5o1axg5ciShoaGGMp999hl//vknFy5cYOfOnbRs2RJzc3Pat2+f0VPNVtevQ2wsmJlBCpdTCCHytaThxocOHcr+/fupVq0aQUFB3LhxI8XyO3fupH379nTt2pUDBw4QHBxMcHAwR48eNZQZM2YMkydPZsaMGezZswc7OzuCgoJ49OiR0bFGjBjB9evXDUufPn2Svd7mzZuNyvj5+WXtBchpr74K1avDo0cwe7apoxFC5Fcqg4oXL67++OOPZOtXrFihvLy8Mno4NWXKFFWiRAllZWWl/P391e7duw3bGjRooEJCQozK79y5UwUEBCi9Xq9KlSqlvv32W/XkyRPD9rZt2yoPDw9lZWWlvLy8VNu2bdWZM2cyFFN0dLQCVHR0dIbPJ722blUKlCpdOtteQgghlFI585l28OBBZWZmlu7y/v7+KjQ01PA8ISFBeXp6qrCwsBTLt2nTRjVt2tRoXUBAgOrRo4dSSqnExETl7u6uxo4da9geFRWl9Hq9WrBggWGdt7e3mjhxYqpxnT9/XgHqwIED6T6X5+XE9X4pP/749MaTkGDqaIQQeURGPtMyXGPRvn17+vbty9atW0lISCAhIYEtW7bw8ccf065duwwnNr179+bixYvExcWxZ88eAgICDNu2bdvG7Od+Walduza7d+/m0aNHnD17li+//NKoz8XChQu5du0acXFxXLlyhYULF1K6dOkMx5XdpBmUEKKgepnhxnft2mVUHiAoKMhQ/vz580RERBiVcXBwICAgINkxR40aRdGiRalRowZjx47lyZMnyV6vefPmuLq6Uq9ePVauXPnS55qrvP8+ODhos3Bv2mTqaIQQ+VCGR4X6+uuvuXDhAg0bNjTMaJ2YmEjHjh0z1MeioJMRoYQQecm7776b5vaoqKh0H+tlhhuPiIhIsXxERIRhe9K61MoA9O3bl1deeYUiRYqwc+dOBg4cyPXr15kwYQIAhQoVYvz48dStWxczMzOWLVtGcHAwK1asMJoU8FmmGrI8w+zstOFmv/tOG3o2KMjUEQkh8pkMJxZWVlYsWrSIb775hoMHD2JjY0OVKlXw9vbOjvjyLamxEELkJQ4ODi/c3rFjxxyK5uX179/f8Lhq1apYWVnRo0cPwsLC0Ov1ODs7G5WpVasW165dY+zYsakmFqYasvyl9OypJRarV8PFi9rkeUIIkUUynFgk8fX1xVd+bn9pUmMhhMhLZs2alWXHepnhxt3d3dMsn/Q3MjLSaBTAyMhIqlevnmosAQEBPHnyhAsXLlCuXLlUy2xKo+nQwIEDjZKRmJgYihcvnmp5kypXDho2hPBw+OEHkJYGQogslOE+Fq1atWL06NHJ1o8ZM4bWrVtnSVD5XUKC1sQVpMZCCFHwvMxw47Vr1zYqD7Bp0yZDeR8fH9zd3Y3KxMTEsGfPnlSPCXDw4EHMzMxwdXVNs0xuG7I8U5KGnv35Z3imCZcQQmRWhmss/vrrL4YNG5ZsfZMmTRg/fnxWxJTvXboE8fGg10Nu/VFLCCGyU//+/QkJCaFmzZr4+/szadKkZMONe3l5ERYWBsDHH39MgwYNGD9+PE2bNmXhwoX8888//PjjjwDodDr69evHN998g6+vLz4+PgwePBhPT0+Cg4MBrQP4nj17eOONNyhcuDC7du3ik08+4YMPPsDJyQmAOXPmYGVlRY0aNQBYvnw5M2fO5Oeff87hK5SNmjcHLy+4ehWWLdM6dQshRBbIcGJx//79FCejs7S0zL0d1nKZpGZQpUvDMwNaCSFEgdG2bVtu3rzJkCFDiIiIoHr16qxfv97Q+frSpUuYmT2tVK9Tpw7z589n0KBBfPnll/j6+rJixQoqV65sKDNgwABiY2Pp3r07UVFR1KtXj/Xr12NtbQ1oNQsLFy5k2LBhxMXF4ePjwyeffGLUjAm0QUouXryIhYUF5cuXZ9GiRbz33ns5cFVyiIUF9OgBQ4ZonbglsRBCZBGdUkplZAd/f3/eeecdhgwZYrR+2LBhrFq1in379mVpgKYQExODg4MD0dHR2VKlPWUK9O0LwcHw++9ZfnghhDCS3Z9pwlieuN7Xr0OJEvDkCRw8CNWqmToiIUQulZHPtAzXWAwePJh3332Xs2fP8uabbwIQHh7O/PnzWbp06ctFXMDIiFBCCCFMysMD3n0XFi/Wai1++MHUEQkh8oEMd95u1qwZK1as4MyZM/Tq1YtPP/2Uq1evsmXLFsqUKZMdMeY7MiKUEEIIk0vqxP3bbxAdbdpYhBD5QoYTC4CmTZuyY8cOYmNjOXfuHG3atOGzzz6jmlSlpovUWAghhDC5116DihXhwQOYO9fU0Qgh8oGXSixAGx0qJCQET09Pxo8fz5tvvsnu3buzMrZ8KS4OLlzQHkuNhRBCCJPR6Z7WWowdq/W7EEKITMhQYhEREcGoUaPw9fWldevW2NvbExcXx4oVKxg1ahS1atXKrjjzjXPnIDERChWCVOaBEkIIIXJGSIg2ROHlyxAUBHfvmjoiIUQelu7EolmzZpQrV47Dhw8zadIkrl27xpQpU7Iztnzp2WZQOp1pYxFCCFHAFSoEGzdqnbmPHIF33oHYWFNHJYTIo9KdWKxbt46uXbsyfPhwmjZtirlMwPBSpOO2EEKIXKVUKdiwARwdYedOeO89bRZXIYTIoHQnFtu3b+fevXv4+fkREBDA1KlTuXXrVnbGli9Jx20hhBC5TpUqsGYN2NjA+vXQqZPWblcIITIg3YnFq6++yk8//cT169fp0aMHCxcuxNPTk8TERDZt2sS9e/eyM858Q2oshBBC5Ep16sCyZdrM3AsWwMcfQ8bm0BVCFHAZHhXKzs6OLl26sH37do4cOcKnn37KqFGjcHV1pXnz5tkRY76SlFhIjYUQQohcp0kTbehZnQ6mToXhw00dkRAiD3np4WYBypUrx5gxY7hy5QoLFizIqpjyrfv34do17bHUWAghhMiV2rfXkgrQEgsZqEUIkU6ZSiySmJubExwczMqVK7PicPnWmTPa36JFoUgR08YihBBCpKpXr6e1FX37wrx5po1HCJEnZEliIdJHmkEJIYTIMwYPhj59tMedOsHatSYNRwiR+0likYNkRCghhBB5hk4HkyZBhw7w5Ik2DO327aaOSgiRi0likYNkRCghhBB5ipkZzJoFTZvCw4faBHqHD5s6KiFELiWJRQ6SGgshhBB5jqUlLF4MdetCdDQEBcHZs6aOSgiRC0likYOkxkIIIUSeZGsLq1dD1aoQEQGNGsH166aOSgiRy0hikUPu3IHbt7XHZcqYNhYhhBAiwxwdYcMGKF0azp3Tai7u3jV1VEKIXEQSixyS1AzKywsKFTJtLEIIIcRLcXeHjRu1v0eOaH0uHjwwdVRCiFxCEoscIs2ghBBC5AulSmk1F46OsHMnvPEGXLpk6qiEELmAJBY5ROawEEIIkW9UrQpr1mjJxd69UKMGrFtn6qiEECYmiUUOkRGhhBBC5Ct16sD+/eDnp3UkfPttGDQIEhJMHZkQwkQkscgh0hRKCCFEvuPjAzt2QK9e2vNvv9VGjIqMNG1cQgiTkMQiByglNRZCCPG8adOmUbJkSaytrQkICGDv3r1pll+yZAnly5fH2tqaKlWqsHbtWqPtSimGDBmCh4cHNjY2BAYGcjrpw/d/SpYsiU6nM1pGjRplVObw4cPUr18fa2trihcvzpgxY7LmhPMrvR6mTYP588HODrZs0ZpG/fWXqSMTQuQwSSxyQEQE3L+vTWBaqpSpoxFCCNNbtGgR/fv3Z+jQoezfv59q1aoRFBTEjRs3Uiy/c+dO2rdvT9euXTlw4ADBwcEEBwdz9OhRQ5kxY8YwefJkZsyYwZ49e7CzsyMoKIhHjx4ZHWvEiBFcv37dsPTp08ewLSYmhkaNGuHt7c2+ffsYO3Ysw4YN48cff8yeC5GftG8Pf/8NFStqc1y8+SaMGQOJiaaOTAiRU5RIJjo6WgEqOjo6S463bZtSoFSpUllyOCGEyJCs/kzLCv7+/io0NNTwPCEhQXl6eqqwsLAUy7dp00Y1bdrUaF1AQIDq0aOHUkqpxMRE5e7ursaOHWvYHhUVpfR6vVqwYIFhnbe3t5o4cWKqcX3//ffKyclJxcXFGdZ9/vnnqly5cuk+t9x4vXPU/ftKffCBduMDpZo1U+rOHVNHJYR4SRn5TJMaixwgzaCEEOKp+Ph49u3bR2BgoGGdmZkZgYGB7Nq1K8V9du3aZVQeICgoyFD+/PnzREREGJVxcHAgICAg2TFHjRpF0aJFqVGjBmPHjuXJkydGr/Paa69hZWVl9DqnTp3irkwGlz52djB3Lvzwg9ZMatUqeOUV2LfP1JEJIbKZJBY5QDpuCyHEU7du3SIhIQE3Nzej9W5ubkRERKS4T0RERJrlk/6+6Jh9+/Zl4cKFbN26lR49ejBy5EgGDBjwwtd59jWeFxcXR0xMjNFS4Ol00L27Ns+Fjw9cuKCNIjV9ulaPIYTIlyxMHUBBIDUWQgiRO/Tv39/wuGrVqlhZWdGjRw/CwsLQ6/UvdcywsDCGDx+eVSHmL6+8og1J27kzrFihjR61fbtWm1GokKmjE0JkMZPXWGR0VJCoqChCQ0Px8PBAr9dTtmzZZCODZPSY2U1qLIQQ4ilnZ2fMzc2JfG5I0sjISNzd3VPcx93dPc3ySX8zckyAgIAAnjx5woULF9J8nWdf43kDBw4kOjrasFy+fDnV1yuQHB1h+XIYNw7MzbXRo/z94fhxU0cmhMhiJk0sMjoqSHx8PG+99RYXLlxg6dKlnDp1ip9++gkvL6+XPmZ2S0iAM2e0x1JjIYQQYGVlhZ+fH+Hh4YZ1iYmJhIeHU7t27RT3qV27tlF5gE2bNhnK+/j44O7ublQmJiaGPXv2pHpMgIMHD2JmZoarq6vhdf766y8eP35s9DrlypXDyckpxWPo9Xrs7e2NFvEcnQ4+/RS2bQNPTzhxAmrV0ibUu3nT1NEJIbJKDnQmT1VGRwWZPn26KlWqlIqPj8+yY6YkK0f0OH9eGxTDykqpJ08yfTghhMiw3DhK0cKFC5Ver1ezZ89Wx48fV927d1eOjo4qIiJCKaXUhx9+qL744gtD+R07digLCws1btw4deLECTV06FBlaWmpjhw5YigzatQo5ejoqP744w91+PBh1aJFC+Xj46MePnyolFJq586dauLEiergwYPq7Nmz6rffflMuLi6qY8eOhmNERUUpNzc39eGHH6qjR4+qhQsXKltbW/XDDz+k+9xy4/XOVSIjlQoMfDpqlK2tUv36KXXliqkjE0KkICOfaSZLLOLi4pS5ubn6/fffjdZ37NhRNW/ePMV9mjRpojp06KC6deumXF1dVaVKldS3336rnvzvG/vLHFMppR49eqSio6MNy+XLl7PsprBhg/a5WaFCpg8lhBAvJbd+0Z0yZYoqUaKEsrKyUv7+/mr37t2GbQ0aNFAhISFG5RcvXqzKli2rrKysVKVKldSaNWuMticmJqrBgwcrNzc3pdfrVcOGDdWpU6cM2/ft26cCAgKUg4ODsra2VhUqVFAjR45Ujx49MjrOoUOHVL169ZRer1deXl5q1KhRGTqv3Hq9c5WEBKWWL1fKz+9pgmFlpVT37kqdOWPq6IQQz8gTicXVq1cVoHbu3Gm0/r///a/y9/dPcZ9y5copvV6vunTpov755x+1cOFCVaRIETVs2LCXPqZSSg0dOlQByZasuClMmaJ9XrZokelDCSHES5EvujlLrncGJCYqtX69UvXrP00wzMyU6tBBqaNHTR2dEELl43ksEhMTcXV15ccff8TPz4+2bdvy1VdfMWPGjEwdNzs73smIUEIIIUQqdDoICoK//tKWxo21mbrnzYPKleHdd2X+CyHyEJMlFi8zKoiHhwdly5bF3NzcsK5ChQpEREQQHx//UseE7O14JyNCCSGEEOlQvz6sWwf//KMlFAC//w41a2oJx19/mTY+IcQLmSyxeJlRQerWrcuZM2dITEw0rPv333/x8PDAysrqpY6Z3aTGQgghhMgAPz9YtgyOHYMPPtCGqN2wARo00JKP9etlkj0hcimTNoXq378/P/30E3PmzOHEiRP07NmT2NhYOnfuDEDHjh0ZOHCgoXzPnj25c+cOH3/8Mf/++y9r1qxh5MiRhIaGpvuYOSk+Hs6f1x5LjYUQQgiRARUrwq+/alX/PXqAlZU2uV6TJtrEe9OnQ1SUqaMUQjzDpDNvt23blps3bzJkyBAiIiKoXr0669evx83NDYBLly5hZvY09ylevDgbNmzgk08+oWrVqnh5efHxxx/z+eefp/uYOencOa2pqJ0deHjk+MsLIYQQeV+pUjBjBgweDOPHa7N2HzyozeLdvz+0agVdu2o1GmZ5quuoEPmOTimpT3xeTEwMDg4OREdHZ6q/xapV0Lw51KgB+/dnYYBCCJEBWfWZJtJHrnc2u3VLq8n45RetuVSSUqWgc2fo1AmKFTNZeELkNxn5TJPUPhtJx20hhBAiizk7wyefwJEjsHs3dO8OhQtrzQQGDwZvb6251NKlEBdn6miFKFAkschGSYmFdNwWQgghsphOBwEBWtOo69dhzhx47TWtDfL69dC6NXh5aUnI0aOmjlaIAkESi2yUNCKU1FgIIYQQ2cjODjp2hD//1H7VGzhQ69x4+zZMmgRVqoC/v5aE3Llj6miFyLckschGUmMhhBBC5DBfXxg5Ei5dgtWroWVLsLCAv/+Gjz6CokW1yfd69IC5c+HMGRm+VogsIp23U5AVHe9iY6FQIe3x7dtQpEgWBiiEEBkgnYlzllzvXOjGDa3D9+zZKTeLcnODOnWgbl1tqVED9PocD1OI3Cgjn2mSWKQgK24Khw5B9epaQnH7dtbGJ4QQGSFfdHOWXO9cLjISdu2CHTu0Zd8+beKpZ+n1UKvW00SjTh2tpkOIAigjn2kmncciP5NmUEIIIUQu5OYGwcHaAvDokZZcJCUaO3dqQ9pu364tScqV0+bKaNgQ3ngDXFxMEb0QuZokFtkkqeO2JBZCCCFELmZt/bRmArT+FqdPP000duyAkyfh1Clt+fFHrVzVqvDmm9rSoAFI7ZQQklhkF5nDIv9ISEjg8ePHpg5DiFSZm5tjYWGBTqczdShC5H06nfarYNmy2oR7oLVp3rkTtmzRlsOHny6TJoG5OdSsqdVmvPmm1nTKxsakpyGEKUhikU2kxiJ/uH//PleuXEG6IoncztbWFg8PD6ysrEwdihD5T9Gi0KyZtgDcvAlbtz5NNE6fhj17tGXkSK2PRp06T2s0atUCS0vTnoMQOUA6b6cgKzreubhoTTT379cGlxB5T0JCAqdPn8bW1hYXFxf5NVjkSkop4uPjuXnzJgkJCfj6+mJmZjySuHQmzllyvQugS5e0RCM8XFuuXTPeXqiQllzUqqXNp+HvD8WKabUjQuRy0nnbxO7e1ZIKkKZQednjx49RSuHi4oKNVGmLXMzGxgZLS0suXrxIfHw81tbWpg5JiIKlRAkICdGWpD4a4eFabcbWrVpTqq1btSWJu/vTJMPfX2tK5eRkunMQIgtIYpENkppBeXo+nctC5F1SUyHygudrKYQQJvJsH42ePSExEY4d0ybo27tXWw4fhogIWLlSW5L4+honG9Wra53LhcgjJLHIBtJxWwghhBAAmJlBlSra0qWLtu7BAzh4UEsykhKOM2e0XyZPn4Z587RyFhZQqRKUKgU+PlCy5NO/JUvKr5ci15HEIhvIHBYivylZsiT9+vWjX79+6Sq/bds23njjDe7evYujo2O2xiaEEHmOra3WubtOnafrbt+Gf/55Wquxd682Y/ihQ9qSEmfn5AlH0l9vbxmZSuQ4SSyygYwIJUzlRc22hg4dyrBhwzJ83L///hs7O7t0l69Tpw7Xr1/HwcEhw68lhBAFUtGiEBSkLaD11bh8WWs2deGCtpw///RvUofOW7e0Wo+UeHsbdxr384PChXPohERBJIlFNpCmUMJUrl+/bni8aNEihgwZwqlTpwzrCj1Tba6UIiEhAQuLF38MuGRwhlkrKyvc3d0ztE9+ER8fL0O+CiEyT6fTOoWXKJHy9ujolBOOpL/37sHFi9qydOnTY1ao8DTRqFVLm+hPr8+ZcxL5nvT2y2JJg0GA1FiInOfu7m5YHBwc0Ol0hucnT56kcOHCrFu3Dj8/P/R6Pdu3b+fs2bO0aNECNzc3ChUqRK1atdi8ebPRcUuWLMmkSZMMz3U6HT///DMtW7bE1tYWX19fVj7TAXHbtm3odDqioqIAmD17No6OjmzYsIEKFSpQqFAhGjdubJQIPXnyhL59++Lo6EjRokX5/PPPCQkJITg4ONXzvX37Nu3bt8fLywtbW1uqVKnCggULjMokJiYyZswYypQpg16vp0SJEnz77beG7VeuXKF9+/YUKVIEOzs7atasyZ49ewDo1KlTstfv168fr7/+uuH566+/Tu/evenXrx/Ozs4E/e/XxgkTJlClShXs7OwoXrw4vXr14v79+0bH2rFjB6+//jq2trY4OTkRFBTE3bt3mTt3LkWLFiUuLs6ofHBwMB9++GGq1yOvmTZtGiVLlsTa2pqAgAD27t2bZvklS5ZQvnx5rK2tqVKlCmvXrjXarpRiyJAheHh4YGNjQ2BgIKeTPpCfExcXR/Xq1dHpdBw8eNCw/sKFC+h0umTL7t27M32+QmQpBweoVg1atIB+/bSJ+v74Q2s2FR2t1WRs3QqjR8N772kJilJw/DjMmQOhoVpyYW+v/Q0N1dYfPw4JCaY+O5FHSWKRxSIjtR8JzMy0vlYi/1AKYmNNs2TlbDNffPEFo0aN4sSJE1StWpX79+/z9ttvEx4ezoEDB2jcuDHNmjXj0qVLaR5n+PDhtGnThsOHD/P222/ToUMH7ty5k2r5Bw8eMG7cOH799Vf++usvLl26xGeffWbYPnr0aObNm8esWbPYsWMHMTExrFixIs0YHj16hJ+fH2vWrOHo0aN0796dDz/80OgL6sCBAxk1ahSDBw/m+PHjzJ8/Hzc3N0CbALFBgwZcvXqVlStXcujQIQYMGEBiYmI6ruRTc+bMwcrKih07djBjxgxAG6Vp8uTJHDt2jDlz5rBlyxYGDBhg2OfgwYM0bNiQihUrsmvXLrZv306zZs1ISEigdevWJCQkGCVrN27cYM2aNXRJ6vyZxy1atIj+/fszdOhQ9u/fT7Vq1QgKCuLGjRsplt+5cyft27ena9euHDhwgODgYIKDgzl69KihzJgxY5g8eTIzZsxgz5492NnZERQUxKNHj5Idb8CAAXh6eqYa3+bNm7l+/bph8fPzy/xJC5FTdDqtadXrr8OAAbBkiVZzEREBq1bB4MHQuDEUKQLx8VpTqu+/h06dtM7iTk5a0tKwIbRtC717w7BhMHUqLFqkDaV76JA2X8dzP4CIAk6JZKKjoxWgoqOjM7zvn38qBUr5+GRDYCJHPXz4UB0/flw9fPhQKaXU/fvav60plvv3Mx7/rFmzlIODg+H51q1bFaBWrFjxwn0rVaqkpkyZYnju7e2tJk6caHgOqEGDBhme379/XwFq3bp1Rq919+5dQyyAOnPmjGGfadOmKTc3N8NzNzc3NXbsWMPzJ0+eqBIlSqgWLVqk95SVUko1bdpUffrpp0oppWJiYpRer1c//fRTimV/+OEHVbhwYXX79u0Ut4eEhCR7/Y8//lg1aNDA8LxBgwaqRo0aL4xryZIlqmjRoobn7du3V3Xr1k21fM+ePVWTJk0Mz8ePH69KlSqlEhMTUyz//Pv1WZn5TMsu/v7+KjQ01PA8ISFBeXp6qrCwsBTLt2nTRjVt2tRoXUBAgOrRo4dSSqnExETl7u5u9B6KiopSer1eLViwwGi/tWvXqvLly6tjx44pQB04cMCw7fz588nWZVRuvN5CpCgxUamzZ5VasECp/v2VqldPKVvbjN+kChdWqlQppfz9lWraVKnPPlPqt9+UOnJEqfh4U5+lyKSMfKZJH4ssJs2gRG5Xs2ZNo+f3799n2LBhrFmzhuvXr/PkyRMePnz4whqLqlWrGh7b2dlhb2+f6q/NALa2tpQuXdrw3MPDw1A+OjqayMhI/P39DdvNzc3x8/NLs/YgISGBkSNHsnjxYq5evUp8fDxxcXHY2toCcOLECeLi4mjYsGGK+x88eJAaNWpQpEiRNM/1RVL6NXvz5s2EhYVx8uRJYmJiePLkCY8ePeLBgwfY2tpy8OBBWrduneoxu3XrRq1atbh69SpeXl7Mnj2bTp065Yt5VeLj49m3bx8DBw40rDMzMyMwMJBdu3aluM+uXbvo37+/0bqgoCBDrdb58+eJiIggMDDQsN3BwYGAgAB27dpFu3btAIiMjKRbt26sWLHC8D5JSfPmzXn06BFly5ZlwIABNG/e/GVPV4jcS6fTmleUKgX/+z/Ckydw8iRcvfq0c/jNmyk/vnVLm6fj3j1tOXdOO8aaNU9fQ6/XakGqVdPm5ahWTVtkxMB8SRKLLCYdt/MvW1t4rol8jr52Vnl+dKfPPvuMTZs2MW7cOMqUKYONjQ3vvfce8fHxaR7H0tLS6LlOp0szCUipvMpkG6+xY8fy3XffMWnSJEN/hn79+hlif9GM6S/abmZmlizGx48fJyv3/DW9cOEC77zzDj179uTbb7+lSJEibN++na5duxIfH4+tre0LX7tGjRpUq1aNuXPn0qhRI44dO8aaZ2/WeditW7dISEgwNElL4ubmxsmTJ1PcJyIiIsXyERERhu1J61Iro5SiU6dOfPTRR9SsWZMLFy4ke51ChQoxfvx46tati5mZGcuWLSM4OJgVK1akmlzExcUZ9YeJiYlJ4+yFyOUsLKByZW15kcREiIoyTjquX4cjR7SmUocPawnH/v3a8ixvb+Nko3p1bZhcmewzT5PEIovJHBb5l04HGRhxNc/YsWMHnTp1omXLloBWg5HSF67s5ODggJubG3///TevvfYaoNVG7N+/n+rVq6e6344dO2jRogUffPABoHXU/vfff6lYsSIAvr6+2NjYEB4ezn/+859k+1etWpWff/6ZO3fupFhr4eLiYtSGH7RajueTpOft27ePxMRExo8fb5gRe/HixcleOzw8nOHDh6d6nP/85z9MmjSJq1evEhgYSPHixdN8XZG2KVOmcO/ePaOakuc5Ozsb1YzUqlWLa9euMXbs2FQTi7CwsDT/HYXIt8zMtH4aRYqk/MUnMVEboSppLo6DB7W/SaNVXbxoPPO4rS0UKwaenuDhof19fvHwyJ8343xCEossltQUSmosRF7h6+vL8uXLadasGTqdjsGDB2e483JW6NOnD2FhYZQpU4by5cszZcoU7t69m2bTH19fX5YuXcrOnTtxcnJiwoQJREZGGhILa2trPv/8cwYMGICVlRV169bl5s2bHDt2jK5du9K+fXtGjhxJcHAwYWFheHh4cODAATw9PalduzZvvvkmY8eOZe7cudSuXZvffvuNo0ePUqNGjTTPpUyZMjx+/JgpU6bQrFkzo07dSQYOHEiVKlXo1asXH330EVZWVmzdupXWrVvj7OwMwPvvv89nn33GTz/9xNy5czN5hXMPZ2dnzM3NiYyMNFofGRmZ6jDF7u7uaZZP+hsZGYmHh4dRmaTkdMuWLezatQv9c0Nr1qxZkw4dOjBnzpwUXzsgIIBNmzalej4DBw40SkZiYmIkCRQCtMSjdGlteffdp+vv3tVqM55NOI4d02Yk//ffp7/SpsbePuWkw8vr6eLhAS/4EUhkPUksslBiIpw5oz2WGguRV0yYMIEuXbpQp04dnJ2d+fzzz03SlOPzzz8nIiKCjh07Ym5uTvfu3QkKCsLc3DzVfQYNGsS5c+cICgrC1taW7t27ExwcTHR0tKHM4MGDsbCwYMiQIVy7dg0PDw8++ugjQJtvY+PGjXz66ae8/fbbPHnyhIoVKzJt2jRAa8M/ePBgBgwYwKNHj+jSpQsdO3bkyJEjaZ5LtWrVmDBhAqNHj2bgwIG89tprhIWF0bFjR0OZsmXLsnHjRr788kv8/f2xsbEhICCA9u3bG8o4ODjQqlUr1qxZk+awu3mNlZUVfn5+hIeHG84rMTGR8PBwevfuneI+tWvXJjw83Gj2902bNlG7dm0AfHx8cHd3Jzw83JBIxMTEsGfPHnr27AnA5MmT+eabbwz7X7t2jaCgIBYtWkRAQECq8R48eNAoWXmeXq9PlqwIIdLg5AQNGmhLksePtTk4rl/XRptKabl6VUs+YmK0JZWmk4DWzMDNzTjZKFbM+LmXl5akiCyjU5lt5JwPxcTE4ODgQHR0NPYZeMNdvKg1D7S0hIcPIY3vQyIPePToEefPn8fHxwdra2tTh1PgJCYmUqFCBdq0acPXX39t6nBMpmHDhlSqVInJkyenWS6t9+vLfqZlp0WLFhESEsIPP/yAv78/kyZNYvHixZw8eRI3Nzc6duyIl5cXYWFhgDbcbIMGDRg1ahRNmzZl4cKFjBw5kv3791P5f23BR48ezahRo5gzZw4+Pj4MHjyYw4cPc/z48RT/D1+4cAEfHx8OHDhgSEaShg5OqpVavnw5gwcP5ueff6Zz587pOrfceL2FyBeU0vpsPJ9wXL8OV65oicfVq9q6J0/Sd8zChaF4cW2eD2/v5IuHR4H/QpeRzzSpschCSTV3pUsX+PegEBl28eJFNm7cSIMGDYiLi2Pq1KmcP3+e999/39ShmcTdu3fZtm0b27Zt4/vvvzd1OFmubdu23Lx5kyFDhhAREUH16tVZv369ofP1pUuXDP1TAOrUqcP8+fMZNGgQX375Jb6+vqxYscKQVIA2N0VsbCzdu3cnKiqKevXqsX79+gz/MPD1119z8eJFLCwsKF++PIsWLeK9997LmhMXQrw8nU6rYbC3h/LlUy+XmKh1JE9KNJ5NOp5doqO1ROX4cW1JiYWFlniklHSUKAHOzlo88sUPkBqLFL3sr03TpmlzyDRvrk1+KfI2qbHIWZcvX6Zdu3YcPXoUpRSVK1dm1KhRhs7cBU3JkiW5e/cugwcPNppIMDV5rcYiP5PrLUQecf++lmBcuqQ1O0n6m7RcuZKxmg9HR21G9PT8dXTUkpKkxCQXDyUuNRYmInNYCPHyihcvzo4dO0wdRq6R0yNzCSFEgVOoEJQrpy0pSUjQmlU9m2w8m3xcugSxsVrZpLk8Ll/OeBwWFk+TjPQsLi5ZOw59FpLEIgvJHBZCCCGEEPmEubnWDKp4cahXL+Uy8fFak6roaG1Oj6iop4/T+nv3Lty+rdWaPHkCERHakl729lr/j+eXpCF5k5Ycrg2RxCILyRwWQgghhBAFiJWVVoPg4vJy+z96pCUYz85mntZy8ybExT0dGevUqbSPb2OTPOEYOTLb5gKRxCKLxMdro6SB1FjkN9INSeQF8j4VQog8yNr66dC36ZE0Mtb160+XpJGxnl8XE6MNU3runLaAVnsxfny2nY4kFlkkIUHrvH32rJYUirwvaf6E+Ph4bGxsTByNEGl78OABwAtnBRdCCJGHPTsyVmp9Q5I8eJA82YiO1vp0ZBNJLLKIjQ306GHqKERWsrCwwNbWlps3b2JpaWk09KUQuYVSigcPHnDjxg0cHR3TnFBQCCFEAWJr+3Tm8xwiiYUQqdDpdHh4eHD+/HkuXrxo6nCESJOjoyPu7u6mDkMIIUQBlisSi2nTpjF27FgiIiKoVq0aU6ZMwd/fP8Wys2fPTjb7qV6v59GjR4bnnTp1Ys6cOUZlgoKCWL9+fdYHL/I1KysrfH19iY+PN3UoQqTK0tJSaiqEEEKYnMkTi0WLFtG/f39mzJhBQEAAkyZNIigoiFOnTuHq6priPvb29px6phe8LoVhtBo3bsysWbMMz/V6fdYHLwoEMzMzmSBPCCGEEOIFTN5ofMKECXTr1o3OnTtTsWJFZsyYga2tLTNnzkx1H51Oh7u7u2Fxc3NLVkav1xuVcXJyys7TEEIIIYQQokAzaWIRHx/Pvn37CAwMNKwzMzMjMDCQXbt2pbrf/fv38fb2pnjx4rRo0YJjx44lK7Nt2zZcXV0pV64cPXv25Pbt29lyDkIIIYQQQggTJxa3bt0iISEhWY2Dm5sbEanMPliuXDlmzpzJH3/8wW+//UZiYiJ16tThypUrhjKNGzdm7ty5hIeHM3r0aP7880+aNGlCQkJCiseMi4sjJibGaBFCCCGEEEKkn8n7WGRU7dq1qV27tuF5nTp1qFChAj/88ANff/01AO3atTNsr1KlClWrVqV06dJs27aNhg0bJjtmWFgYw4cPT7ZeEgwhRH6Q9Fkmk+jljKTrLPcQIUR+kJF7iEkTC2dnZ8zNzYmMjDRaHxkZme5hEy0tLalRowZnzpxJtUypUqVwdnbmzJkzKSYWAwcOpH///obnV69epWLFihQvXjydZyKEELnfvXv3cHBwMHUY+d69e/cA5B4ihMhX0nMPMWliYWVlhZ+fH+Hh4QQHBwOQmJhIeHg4vXv3TtcxEhISOHLkCG+//XaqZa5cucLt27fx8PBIcbterzcaNapQoUJcvnyZwoULpzjilNCy1+LFi3P58mXs7e1NHU6uJdcpfeQ6pc/LXielFPfu3cPT0zMboxNJPD095R7yAvJ/Pn3kOqWPXKf0yYl7iMmbQvXv35+QkBBq1qyJv78/kyZNIjY21jBXRceOHfHy8iIsLAyAESNG8Oqrr1KmTBmioqIYO3YsFy9e5D//+Q+gdewePnw4rVq1wt3dnbNnzzJgwADKlClDUFBQumIyMzOjWLFi2XPC+Yy9vb38J04HuU7pI9cpfV7mOklNRc6Re0j6yf/59JHrlD5yndInO+8hJk8s2rZty82bNxkyZAgRERFUr16d9evXGzp0X7p0CTOzp33M7969S7du3YiIiMDJyQk/Pz927txJxYoVATA3N+fw4cPMmTOHqKgoPD09adSoEV9//bXMZSGEEEIIIUQ20SnpzSdeQkxMDA4ODkRHR8uvA2mQ65Q+cp3SR66TyC/kvZw+cp3SR65T+uTEdTL5BHkib9Lr9QwdOlRqgV5ArlP6yHVKH7lOIr+Q93L6yHVKH7lO6ZMT10lqLIQQQgghhBCZJjUWQgghhBBCiEyTxEIIIYQQQgiRaZJYCCGEEEIIITJNEguRIcOGDUOn0xkt5cuXN3VYJvfXX3/RrFkzPD090el0rFixwmi7UoohQ4bg4eGBjY0NgYGBnD592jTBmtCLrlOnTp2Svb8aN25smmBNJCwsjFq1alG4cGFcXV0JDg7m1KlTRmUePXpEaGgoRYsWpVChQrRq1YrIyEgTRSxE+sk9JGVyD0kfuYe8mKnvIZJYiAyrVKkS169fNyzbt283dUgmFxsbS7Vq1Zg2bVqK28eMGcPkyZOZMWMGe/bswc7OjqCgIB49epTDkZrWi64TQOPGjY3eXwsWLMjBCE3vzz//JDQ0lN27d7Np0yYeP35Mo0aNiI2NNZT55JNPWLVqFUuWLOHPP//k2rVrvPvuuyaMWoj0k3tIcnIPSR+5h7yYye8hSogMGDp0qKpWrZqpw8jVAPX7778bnicmJip3d3c1duxYw7qoqCil1+vVggULTBBh7vD8dVJKqZCQENWiRQuTxJNb3bhxQwHqzz//VEpp7x1LS0u1ZMkSQ5kTJ04oQO3atctUYQqRLnIPeTG5h6SP3EPSJ6fvIVJjITLs9OnTeHp6UqpUKTp06MClS5dMHVKudv78eSIiIggMDDSsc3BwICAggF27dpkwstxp27ZtuLq6Uq5cOXr27Mnt27dNHZJJRUdHA1CkSBEA9u3bx+PHj43eT+XLl6dEiRLyfhJ5gtxDMkbuIRkj9xBjOX0PkcRCZEhAQACzZ89m/fr1TJ8+nfPnz1O/fn3u3btn6tByrYiICADc3NyM1ru5uRm2CU3jxo2ZO3cu4eHhjB49mj///JMmTZqQkJBg6tBMIjExkX79+lG3bl0qV64MaO8nKysrHB0djcrK+0nkBXIPyTi5h6Sf3EOMmeIeYpHpI4gCpUmTJobHVatWJSAgAG9vbxYvXkzXrl1NGJnID9q1a2d4XKVKFapWrUrp0qXZtm0bDRs2NGFkphEaGsrRo0elDbrIN+QeIrKT3EOMmeIeIjUWIlMcHR0pW7YsZ86cMXUouZa7uztAshEXIiMjDdtEykqVKoWzs3OBfH/17t2b1atXs3XrVooVK2ZY7+7uTnx8PFFRUUbl5f0k8iK5h7yY3ENentxDcv4eIomFyJT79+9z9uxZPDw8TB1KruXj44O7uzvh4eGGdTExMezZs4fatWubMLLc78qVK9y+fbtAvb+UUvTu3Zvff/+dLVu24OPjY7Tdz88PS0tLo/fTqVOnuHTpkryfRJ4j95AXk3vIy5N7SM7fQ6QplMiQzz77jGbNmuHt7c21a9cYOnQo5ubmtG/f3tShmdT9+/eNfhE5f/48Bw8epEiRIpQoUYJ+/frxzTff4Ovri4+PD4MHD8bT05Pg4GDTBW0CaV2nIkWKMHz4cFq1aoW7uztnz55lwIABlClThqCgIBNGnbNCQ0OZP38+f/zxB4ULFza0eXVwcMDGxgYHBwe6du1K//79KVKkCPb29vTp04fatWvz6quvmjh6IdIm95CUyT0kfeQe8mImv4dkelwpUaC0bdtWeXh4KCsrK+Xl5aXatm2rzpw5Y+qwTG7r1q0KSLaEhIQopbThAgcPHqzc3NyUXq9XDRs2VKdOnTJt0CaQ1nV68OCBatSokXJxcVGWlpbK29tbdevWTUVERJg67ByV0vUB1KxZswxlHj58qHr16qWcnJyUra2tatmypbp+/brpghYineQekjK5h6SP3ENezNT3EN3/ghBCCCGEEEKIlyZ9LIQQQgghhBCZJomFEEIIIYQQItMksRBCCCGEEEJkmiQWQgghhBBCiEyTxEIIIYQQQgiRaZJYCCGEEEIIITJNEgshhBBCCCFEpkliIYQQQgghhMg0SSyEyAN0Oh0rVqwwdRhCCCHyILmHiJwiiYUQL9CpUyd0Ol2ypXHjxqYOTQghRC4n9xBRkFiYOgAh8oLGjRsza9Yso3V6vd5E0QghhMhL5B4iCgqpsRAiHfR6Pe7u7kaLk5MToFUxT58+nSZNmmBjY0OpUqVYunSp0f5HjhzhzTffxMbGhqJFi9K9e3fu379vVGbmzJlUqlQJvV6Ph4cHvXv3Ntp+69YtWrZsia2tLb6+vqxcudKw7e7du3To0AEXFxdsbGzw9fVNdhMTQghhGnIPEQWFJBZCZIHBgwfTqlUrDh06RIcOHWjXrh0nTpwAIDY2lqCgIJycnPj7779ZsmQJmzdvNvrQnz59OqGhoXTv3p0jR46wcuVKypQpY/Qaw4cPp02bNhw+fJi3336bDh06cOfOHcPrHz9+nHXr1nHixAmmT5+Os7Nzzl0AIYQQL03uISLfUEKINIWEhChzc3NlZ2dntHz77bdKKaUA9dFHHxntExAQoHr27KmUUurHH39UTk5O6v79+4bta9asUWZmZioiIkIppZSnp6f66quvUo0BUIMGDTI8v3//vgLUunXrlFJKNWvWTHXu3DlrTlgIIUSWkXuIKEikj4UQ6fDGG28wffp0o3VFihQxPK5du7bRttq1a3Pw4EEATpw4QbVq1bCzszNsr1u3LomJiZw6dQqdTse1a9do2LBhmjFUrVrV8NjOzg57e3tu3LgBQM+ePWnVqhX79++nUaNGBAcHU6dOnZc6VyGEEFlL7iGioJDEQoh0sLOzS1atnFVsbGzSVc7S0tLouU6nIzExEYAmTZpw8eJF1q5dy6ZNm2jYsCGhoaGMGzcuy+MVQgiRMXIPEQWF9LEQIgvs3r072fMKFSoAUKFCBQ4dOkRsbKxh+44dOzAzM6NcuXIULlyYkiVLEh4enqkYXFxcCAkJ4bfffmPSpEn8+OOPmTqeEEKInCH3EJFfSI2FEOkQFxdHRESE0ToLCwtD57YlS5ZQs2ZN6tWrx7x589i7dy+//PILAB06dGDo0KGEhIQwbNgwbt68SZ8+ffjwww9xc3MDYNiwYXz00Ue4urrSpEkT7t27x44dO+jTp0+64hsyZAh+fn5UqlSJuLg4Vq9ebbgpCSGEMC25h4iCQhILIdJh/fr1eHh4GK0rV64cJ0+eBLTRNhYuXEivXr3w8PBgwYIFVKxYEQBbW1s2bNjAxx9/TK1atbC1taVVq1ZMmDDBcKyQkBAePXrExIkT+eyzz3B2dua9995Ld3xWVlYMHDiQCxcuYGNjQ/369Vm4cGEWnLkQQojMknuIKCh0Sill6iCEyMt0Oh2///47wcHBpg5FCCFEHiP3EJGfSB8LIYQQQgghRKZJYiGEEEIIIYTINGkKJYQQQgghhMg0qbEQQgghhBBCZJokFkIIIYQQQohMk8RCCCGEEEIIkWmSWAghhBBCCCEyTRILIYQQQgghRKZJYiGEEEIIIYTINEkshBBCCCGEEJkmiYUQQgghhBAi0ySxEEIIIYQQQmTa/wOPOfGSPb8yggAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8,3))\n",
    "\n",
    "epochs = range(1, len(loss_hist) + 1)\n",
    "\n",
    "# plot accuracy over epochs\n",
    "axs[0].plot(epochs, acc_hist, 'b', label='Training accuracy')\n",
    "axs[0].set_title('Training Accuracy over epochs')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend()\n",
    "\n",
    "# plot loss over epochs\n",
    "axs[1].plot(epochs, loss_hist, 'r', label='Training loss')\n",
    "axs[1].set_title('Training Loss over epochs')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Interpreting training results**\n",
    "1. Did the training converge? Why do you think so?\n",
    "2. After how many epochs could we have stopped the training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "1. Yes, it did. The loss value has stabilized (it does not decrease significantly with additional training). The accuracy has also plateaued and further training does not lead to improvements. And like the general trend over the epochs, when both values have stabilized.\n",
    "2. It seems after 16 epochs we could have stopped the training. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Test network on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test observations: 73 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test observations: {100 * correct // total} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performance is significantly better than random chance, which would be a 33% accuracy when randomly selecting from 3 classes. It appears that the network has learned something meaningful.\n",
    "\n",
    "Lastly, we want to create a short GIF showing our agent playing the breakout task. You don't need to understand the details of how this function works yet. Notice: It saves each game frame as breakout_minatar.png and removes the file in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "/var/folders/2n/wg5qsl597wd67jw28g56nzgm0000gn/T/ipykernel_70471/2221148967.py:34: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread('breakout_minatar.png'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "def create_gif():\n",
    "    \"\"\" Creates a GIF of the agent playing in the current folder. \"\"\"#\n",
    "    # Create environment and reset\n",
    "    env = gym.make('MinAtar/Breakout-v1')\n",
    "    obs, info = env.reset()\n",
    "    images = []\n",
    "\n",
    "    for i in range(1_000):\n",
    "        # Get action\n",
    "        obs = torch.tensor(obs, dtype=torch.float).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            obs = obs.cuda()\n",
    "        act_probs = net(obs)\n",
    "        act = np.argmax(act_probs.detach().cpu().numpy())\n",
    "\n",
    "        # Step the environment\n",
    "        obs, reward, terminated, truncated, info = env.step(act)\n",
    "        \n",
    "        # Render as image\n",
    "        n_channels = 4\n",
    "        obs = obs.astype(np.float32)\n",
    "        cmap = sns.color_palette(\"cubehelix\", n_channels)\n",
    "        cmap.insert(0, (0,0,0))\n",
    "        cmap = colors.ListedColormap(cmap)\n",
    "        numerical_state = np.amax(obs * np.reshape(np.arange(n_channels) + 1, (1,1,-1)), 2) + 0.5\n",
    "        numerical_state = numerical_state.repeat(48, axis=0).repeat(48, axis=1)\n",
    "        plt.imsave('breakout_minatar.png', numerical_state, cmap=cmap)\n",
    "        images.append(imageio.imread('breakout_minatar.png'))\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    # Save GIF\n",
    "    imageio.mimsave('breakout.gif', images, loop=0, fps=20)\n",
    "    os.remove('breakout_minatar.png')\n",
    "    env.close()\n",
    "\n",
    "create_gif()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6 Additional questions**\n",
    "\n",
    "So far, the hyperparameters for the training were given. We now want to investigate how different hyperparameters influence the training results. Additionally, there are many techniques and architectures to improve robustness and efficiency of neural network training. It is time for you to explore and find a few more.\n",
    "\n",
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Ablation studies: Effect of hyperparameters**\n",
    "1. Learning rate: Test different learning rates of the Adam Optimizer. What happens if the learaning rate is too large/too small?\n",
    "2. Epochs: Can you think of any drawbacks of training a network for too many epochs? If yes, how can we adjust the training to cope for these drawbacks?\n",
    "3. Number of latent channels: Try different values for the number of latent channels. What happens if you increase/decrease the number of channels? Does an increase of channels increase the paramters of a convolutional layer or linear layer more and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "1. The learning rate **too large**: the optimization algorithm can overshoot the minimum of the loss function.The optimization process might encounter difficulties in reaching convergence, or it might exhibit oscillations around the optimal parameter values.\n",
    "The learning rate **too small**: the optimization process can become very slow, and the model may take a long time to converge. The model could become stuck in local minima, saddle points, or plateaus, potentially leading to training that demands an impractical amount of time or fails to achieve a satisfactory solution.\n",
    "2. Too many epochs can lead to the following problems:\n",
    "   - Overfitting. Extended training duration might lead the model to memorize the training data, capturing irrelevant details and noise that do not generalize effectively to new, unseen data.\n",
    "   - Computational Cost. Continuing training for an excessive number of epochs results in unnecessary computational expenses, particularly when the model has already reached convergence.\n",
    "   - Memory Usage. Excessive training epochs can lead to increased memory usage, particularly when working with large datasets or complex models.\n",
    "   - Diminishing Returns. After a certain point, the model may stop improving significantly on the training set, leading to diminishing returns.\n",
    "3. **Increasing** the number of latent channels can improve the model's ability to represent complex features and capture intricate patterns within the data. An increase in channels leads to **a proportional increase in the number of parameters in the convolutional layer**. Each filter in the layer connects to the input channels, contributing to the overall parameter count.\n",
    "**Decreasing** the number of channels could lead to a decrease in the model's capacity, potentially compromising its capability to capture complex features. A decrease in latent channels leads to a reduction in the number of parameters, as each filter connects to fewer input channels. This reduction in parameters may help control model complexity and prevent overfitting, especially in scenarios with limited data.\n",
    "Increasing the number of channels contributes more significantly to the parameters of a convolutional layer compared to a linear layer. This is because each channel in a convolutional layer is associated with a set of learnable filters, and the parameter count scales with both the number of input channels and the number of filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">**EXERCISE**</span>: **Robustness and efficiency**\n",
    "1. We investigated the effect of layer channels. What other way can you think of to make a neural net more complex/expressive than increasing the channel sizes?\n",
    "2. What is underfitting/overfitting? Explain in a few short sentences.\n",
    "3. Name one technique to prevent underfitting, and one to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "1. Possible ways:\n",
    "   - Adding more layers (increasing the depth of the NN).\n",
    "   - Adding more neurons (increasing the width).\n",
    "   - Use skip connection to allow the direct flow of information across layers.\n",
    "   - Use different architectures (CNNs, RNNs)\n",
    "   - Use dropout as a regularization technique. \n",
    "3. **Underfitting** happens when a model is too simple to grasp the patterns in the training data, resulting in poor performance on both the training set and new, unseen data. **Overfitting** happens when a model is too complex, capturing noise and specificities in the training data that don't generalize well to new data. It performs well on the training set but poorly on new data due to a lack of generalization.\n",
    "4. **For underfitting**: increase a model complexity (adding more features to the input, use deeper neural networks -- more hidden layers). **For overfitting**: regularization - adding a penalty term to the loss function (widely used L1 or L2 regularization methods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
